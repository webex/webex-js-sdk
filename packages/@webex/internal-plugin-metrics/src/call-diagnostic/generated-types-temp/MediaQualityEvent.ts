/* eslint-disable */
/**
 * This file was automatically generated by json-schema-to-typescript.
 * DO NOT MODIFY IT BY HAND. Instead, modify the source JSONSchema file,
 * and run json-schema-to-typescript to regenerate this file.
 */

/**
 * Media Quality Events from media services (e.g. Linus, Edonus, Clients)
 */
export interface MediaQualityEvent {
  canProceed: boolean;
  state?: string;
  mediaType?: "audio" | "video" | "share" | "share_audio" | "whiteboard" | "gamestate";
  csi?: number;
  /**
   * media capability for both transmit and receive
   */
  mediaCapabilities?: {
    /**
     * explicit indication of media capabilities. true=supported
     */
    tx: {
      audio: boolean;
      video: boolean;
      share: boolean;
      share_audio: boolean;
      whiteboard: boolean;
      gamestate?: boolean;
    };
    /**
     * explicit indication of media capabilities. true=supported
     */
    rx: {
      audio: boolean;
      video: boolean;
      share: boolean;
      share_audio: boolean;
      whiteboard: boolean;
      gamestate?: boolean;
    };
  };
  mediaLines?: {
    mediaType: "audio" | "video" | "share" | "share_audio" | "whiteboard" | "gamestate";
    remoteIP?: string;
    localIP?: string;
    localNetworkPrefix?: string;
    localPort?: number;
    remotePort?: number;
    protocol: "udp" | "tcp" | "xtls" | "unknown";
    direction: "sendrecv" | "sendonly" | "recvonly" | "inactive";
    clusterName?: string;
    status?: "succeeded" | "in-progress" | "failed";
    failureReason?: "network" | "transport" | "rejected" | "timeout" | "notstarted" | "succeeded";
    failureDescription?: string;
    errorCode?: number;
    mediaLineData?: {};
    iceMangled?: boolean;
    transactionId?: string;
    ufrag?: string;
    sentReqTime?: string;
    recvRespTime?: string;
  }[];
  /**
   * allows client to specify media preferences
   */
  clientMediaPreferences?: {
    preferTranscoding: boolean;
  };
  pstnAudioType?: "dial-in" | "dial-out";
  success?: boolean;
  isTranscoded?: boolean;
  isGatewayed?: boolean;
  isComposed?: boolean;
  /**
   * determine how the events are processed as well as how the reports are aggregated and sliced
   */
  registrationMode?: "SIP" | "Cloud" | "CloudAware";
  /**
   * protocols used to help determine how the events are processed as well as how the reports are aggregated and sliced
   */
  protocol?: "SIP" | "H323" | "Locus" | "WebRTC";
  /**
   * The underlying service provider of the call.
   */
  meetingPlatform?: "MsTeams" | "GoogleMeet" | "Zoom" | "Webex";
  labels?: string[];
  webexServiceType?: "MC" | "EC" | "SC" | "TC" | "AA" | "RA" | "NBR" | "WRF" | "HOL";
  /**
   * this defines the sub service type
   */
  webexSubServiceType?: "PMR" | "Event" | "Training" | "ScheduleMeeting" | "ScheduledMeeting" | "Webinar" | "others";
  ivrDialogType?:
    | "MEDIA_ON_HOLD"
    | "ANNOUNCEMENT"
    | "TONE"
    | "COLLECT_PIN"
    | "PROMPT"
    | "MEDIA_SERVICE_AGENT"
    | "COLLECT";
  ivrDialogResult?:
    | "SUCCESS"
    | "FAILURE"
    | "HOST_PIN_MATCH"
    | "GUEST_PIN_MATCH"
    | "PANELIST_PIN_MATCH"
    | "NO_MATCH"
    | "INVALID_PIN";
  callType?:
    | "VIDEO_DIALIN"
    | "VIDEO_DIALOUT"
    | "CASCADE"
    | "HYBRID_CASCADE"
    | "PSTN_SIP"
    | "PSTN_DIALIN"
    | "PSTN_DIALOUT"
    | "PSTN_ONLY_DIALIN"
    | "PSTN_ONLY_DIALOUT"
    | "H323"
    | "H323_IP"
    | "SIP_ENTERPRISE"
    | "SIP_MOBILE"
    | "SIP_NATIONAL"
    | "SIP_INTERNATIONAL"
    | "SIP_EMERGENCY"
    | "SIP_OPERATOR"
    | "SIP_SHORTCODE"
    | "SIP_TOLLFREE"
    | "SIP_PREMIUM"
    | "SIP_URI"
    | "SIP_INBOUND"
    | "UNKNOWN"
    | "ZTM"
    | "SIP_MEETING";
  eventData?: {};
  derivedSipClientType?:
    | "SIP_CE_SINGLE_SCREEN"
    | "SIP_CE_MULTI_SCREEN"
    | "SIP_JABBER"
    | "SIP_TIP_SINGLE_SCREEN"
    | "SIP_TIP_THREE_SCREEN"
    | "SIP_PSTN"
    | "SIP_OTHER"
    | "SIP_WEBEX_CASCADE"
    | "SIP_NONE";
  /**
   * this defines the major client types
   */
  derivedClientType?:
    | "MEETING_CENTER"
    | "EVENT_CENTER"
    | "TRAINING_CENTER"
    | "TEAMS_CLIENT"
    | "TEAMS_DEVICE"
    | "TEAMS_SHARE"
    | "SIP"
    | "RECORDING"
    | "CLOUD_AWARE_SIP"
    | "TEAMS_WXC_CLIENT"
    | "WXC_CLIENT"
    | "WXC_DEVICE"
    | "WEBEX_JS_SDK"
    | "VOICEA_CLIENT"
    | "CISCO_SIP_GW"
    | "WEBEX_SDK"
    | "CPAAS_THIRD_PARTY_SDK"
    | "WXC_THIRD_PARTY";
  /**
   * this defines the sub types of clients
   */
  derivedSubClientType?:
    | "DESKTOP_APP"
    | "DESKTOP_APP_VDI"
    | "DEVICE_CURRENT"
    | "DEVICE_LEGACY_2020"
    | "HVDI_APP"
    | "MOBILE_APP"
    | "VDI_APP"
    | "WEB_APP"
    | "MOBILE_NETWORK"
    | "HOLOGRAM_HEADSET_APP";
  serverRole?:
    | "CONFERENCE"
    | "TRANSCODER"
    | "WHITEBOARD_INJECTOR"
    | "MS_TEAMS_CONFERENCE"
    | "RECORDING"
    | "GATEWAY"
    | "GATEWAY_CLIENT_SIDE"
    | "UNKNOWN"
    | "HOLOGRAM_RENDER";
  reconnect?: boolean;
  retryCount?: number;
  meetSimple?: boolean;
  /**
   * represents media quality status report such as no media or drop out
   */
  mediaStatus?: {
    mediaType?: "audio" | "video" | "share" | "share_audio" | "whiteboard";
    mediaSuccess?: boolean;
    shareType?:
      | "cb-normal-share"
      | "ce-airplay-share"
      | "ce-direct-share"
      | "ce-gui-loopback-share"
      | "ce-input-source-share"
      | "ce-input-source-share-hdmi"
      | "ce-input-source-share-usbc"
      | "ce-jpg-share"
      | "ce-miracast-share"
      | "mcs-normal-share"
      | "mcs-normal-audio-share"
      | "mcs-hfps-share"
      | "mcs-hfps-audio-share";
    isTransmitter?: boolean;
    audioJoinType?:
      | "phone-call-in"
      | "phone-call-back"
      | "voip"
      | "device-call-back"
      | "never-join-audio"
      | "tried-but-never-join";
    /**
     * indicates transport type used
     */
    transportType?: "UDP" | "TCP" | "xTLS" | "TLS";
    additionalData?: {};
  };
  shareInstanceId?: string;
  hologramStreamId?: string;
  /**
   * represents all of the properities that could cause delay during media setup process.
   */
  audioSetupDelay?: {
    floorReqSentReceived?: number;
    floorRespSentReceived?: number;
    mediaType?: "audio" | "video" | "share" | "share_audio" | "whiteboard";
    txReqFloorGranted?: number;
    txSessionCreateConfirm?: number;
    txApeEnrollConfirm?: number;
    txUIDelay?: number;
    txScreenCaptureDelay?: number;
    txScreenCaptureDelayReasonCode?: number;
    txShareStartOverallDelay?: number;
    rx1stPacket2RenderDelay?: number;
    rxGranted2RenderDelay?: number;
    rxFailFrameNumB4Success?: number;
    e2eFirstFrameDelay?: number;
    CBSessionRespToLocusFloorGrantDelay?: number;
    CBShareReceiveToServerShareTransmitDelay?: number;
    CBShareReceiveToTPGWFirstKeyFrameDelay?: number;
    TPGWFirstKeyFrameToServerShareTransmitDelay?: number;
    MCSSessionActivateToLocusFloorGrantDelay?: number;
    ServerShareInitiateToLocusFloorGrantDelay?: number;
    LocusFloorGrantToCBSessionStartDelay?: number;
    ServerShareReceiveToTPGWFirstKeyFrameDelay?: number;
    LocusFloorGrantToTPGWFloorGrantDelay?: number;
    LocusFloorGrantToReceiverNotificationDelay?: number;
    CBShareSessionRespDelay?: number;
    LocusShareFloorGrantRespDelay?: number;
    ServerShareFloorGrantRespDelay?: number;
    joinRespRxStart?: number;
    joinRespTxStart?: number;
    maxRemoteLossRate?: number;
    media2SignalDelay?: number;
    warholDownloadTime?: number;
    contentDownloadTime?: number;
    boardCreationTime?: number;
    totalBoardServiceRespDelay?: number;
  };
  /**
   * represents all of the properities that could cause delay during media setup process.
   */
  videoSetupDelay?: {
    floorReqSentReceived?: number;
    floorRespSentReceived?: number;
    mediaType?: "audio" | "video" | "share" | "share_audio" | "whiteboard";
    txReqFloorGranted?: number;
    txSessionCreateConfirm?: number;
    txApeEnrollConfirm?: number;
    txUIDelay?: number;
    txScreenCaptureDelay?: number;
    txScreenCaptureDelayReasonCode?: number;
    txShareStartOverallDelay?: number;
    rx1stPacket2RenderDelay?: number;
    rxGranted2RenderDelay?: number;
    rxFailFrameNumB4Success?: number;
    e2eFirstFrameDelay?: number;
    CBSessionRespToLocusFloorGrantDelay?: number;
    CBShareReceiveToServerShareTransmitDelay?: number;
    CBShareReceiveToTPGWFirstKeyFrameDelay?: number;
    TPGWFirstKeyFrameToServerShareTransmitDelay?: number;
    MCSSessionActivateToLocusFloorGrantDelay?: number;
    ServerShareInitiateToLocusFloorGrantDelay?: number;
    LocusFloorGrantToCBSessionStartDelay?: number;
    ServerShareReceiveToTPGWFirstKeyFrameDelay?: number;
    LocusFloorGrantToTPGWFloorGrantDelay?: number;
    LocusFloorGrantToReceiverNotificationDelay?: number;
    CBShareSessionRespDelay?: number;
    LocusShareFloorGrantRespDelay?: number;
    ServerShareFloorGrantRespDelay?: number;
    joinRespRxStart?: number;
    joinRespTxStart?: number;
    maxRemoteLossRate?: number;
    media2SignalDelay?: number;
    warholDownloadTime?: number;
    contentDownloadTime?: number;
    boardCreationTime?: number;
    totalBoardServiceRespDelay?: number;
  };
  /**
   * represents all of the properities that could cause delay during media setup process.
   */
  shareSetupDelay?: {
    floorReqSentReceived?: number;
    floorRespSentReceived?: number;
    mediaType?: "audio" | "video" | "share" | "share_audio" | "whiteboard";
    txReqFloorGranted?: number;
    txSessionCreateConfirm?: number;
    txApeEnrollConfirm?: number;
    txUIDelay?: number;
    txScreenCaptureDelay?: number;
    txScreenCaptureDelayReasonCode?: number;
    txShareStartOverallDelay?: number;
    rx1stPacket2RenderDelay?: number;
    rxGranted2RenderDelay?: number;
    rxFailFrameNumB4Success?: number;
    e2eFirstFrameDelay?: number;
    CBSessionRespToLocusFloorGrantDelay?: number;
    CBShareReceiveToServerShareTransmitDelay?: number;
    CBShareReceiveToTPGWFirstKeyFrameDelay?: number;
    TPGWFirstKeyFrameToServerShareTransmitDelay?: number;
    MCSSessionActivateToLocusFloorGrantDelay?: number;
    ServerShareInitiateToLocusFloorGrantDelay?: number;
    LocusFloorGrantToCBSessionStartDelay?: number;
    ServerShareReceiveToTPGWFirstKeyFrameDelay?: number;
    LocusFloorGrantToTPGWFloorGrantDelay?: number;
    LocusFloorGrantToReceiverNotificationDelay?: number;
    CBShareSessionRespDelay?: number;
    LocusShareFloorGrantRespDelay?: number;
    ServerShareFloorGrantRespDelay?: number;
    joinRespRxStart?: number;
    joinRespTxStart?: number;
    maxRemoteLossRate?: number;
    media2SignalDelay?: number;
    warholDownloadTime?: number;
    contentDownloadTime?: number;
    boardCreationTime?: number;
    totalBoardServiceRespDelay?: number;
  };
  /**
   * represents all of the properities that could cause delay during media setup process.
   */
  shareAudioSetupDelay?: {
    floorReqSentReceived?: number;
    floorRespSentReceived?: number;
    mediaType?: "audio" | "video" | "share" | "share_audio" | "whiteboard";
    txReqFloorGranted?: number;
    txSessionCreateConfirm?: number;
    txApeEnrollConfirm?: number;
    txUIDelay?: number;
    txScreenCaptureDelay?: number;
    txScreenCaptureDelayReasonCode?: number;
    txShareStartOverallDelay?: number;
    rx1stPacket2RenderDelay?: number;
    rxGranted2RenderDelay?: number;
    rxFailFrameNumB4Success?: number;
    e2eFirstFrameDelay?: number;
    CBSessionRespToLocusFloorGrantDelay?: number;
    CBShareReceiveToServerShareTransmitDelay?: number;
    CBShareReceiveToTPGWFirstKeyFrameDelay?: number;
    TPGWFirstKeyFrameToServerShareTransmitDelay?: number;
    MCSSessionActivateToLocusFloorGrantDelay?: number;
    ServerShareInitiateToLocusFloorGrantDelay?: number;
    LocusFloorGrantToCBSessionStartDelay?: number;
    ServerShareReceiveToTPGWFirstKeyFrameDelay?: number;
    LocusFloorGrantToTPGWFloorGrantDelay?: number;
    LocusFloorGrantToReceiverNotificationDelay?: number;
    CBShareSessionRespDelay?: number;
    LocusShareFloorGrantRespDelay?: number;
    ServerShareFloorGrantRespDelay?: number;
    joinRespRxStart?: number;
    joinRespTxStart?: number;
    maxRemoteLossRate?: number;
    media2SignalDelay?: number;
    warholDownloadTime?: number;
    contentDownloadTime?: number;
    boardCreationTime?: number;
    totalBoardServiceRespDelay?: number;
  };
  /**
   * represents all of the properities that could cause delay during media setup process.
   */
  whiteboardSetupDelay?: {
    floorReqSentReceived?: number;
    floorRespSentReceived?: number;
    mediaType?: "audio" | "video" | "share" | "share_audio" | "whiteboard";
    txReqFloorGranted?: number;
    txSessionCreateConfirm?: number;
    txApeEnrollConfirm?: number;
    txUIDelay?: number;
    txScreenCaptureDelay?: number;
    txScreenCaptureDelayReasonCode?: number;
    txShareStartOverallDelay?: number;
    rx1stPacket2RenderDelay?: number;
    rxGranted2RenderDelay?: number;
    rxFailFrameNumB4Success?: number;
    e2eFirstFrameDelay?: number;
    CBSessionRespToLocusFloorGrantDelay?: number;
    CBShareReceiveToServerShareTransmitDelay?: number;
    CBShareReceiveToTPGWFirstKeyFrameDelay?: number;
    TPGWFirstKeyFrameToServerShareTransmitDelay?: number;
    MCSSessionActivateToLocusFloorGrantDelay?: number;
    ServerShareInitiateToLocusFloorGrantDelay?: number;
    LocusFloorGrantToCBSessionStartDelay?: number;
    ServerShareReceiveToTPGWFirstKeyFrameDelay?: number;
    LocusFloorGrantToTPGWFloorGrantDelay?: number;
    LocusFloorGrantToReceiverNotificationDelay?: number;
    CBShareSessionRespDelay?: number;
    LocusShareFloorGrantRespDelay?: number;
    ServerShareFloorGrantRespDelay?: number;
    joinRespRxStart?: number;
    joinRespTxStart?: number;
    maxRemoteLossRate?: number;
    media2SignalDelay?: number;
    warholDownloadTime?: number;
    contentDownloadTime?: number;
    boardCreationTime?: number;
    totalBoardServiceRespDelay?: number;
  };
  isFocus?: boolean;
  processingDelay?: number;
  shareType?:
    | "cb-normal-share"
    | "ce-airplay-share"
    | "ce-direct-share"
    | "ce-gui-loopback-share"
    | "ce-input-source-share"
    | "ce-input-source-share-hdmi"
    | "ce-input-source-share-usbc"
    | "ce-jpg-share"
    | "ce-miracast-share"
    | "mcs-normal-share"
    | "mcs-normal-audio-share"
    | "mcs-hfps-share"
    | "mcs-hfps-audio-share";
  isShareBeingTakenOver?: boolean;
  floorBeneficiaryUpdated?: boolean;
  meetingJoinedTime?: string;
  meetingScheduledTime?: string;
  e2eeKeyEpoch?: number;
  e2eeDecompressRatio?: number;
  keyResponses?: {
    gotKeyTime?: number;
    useKeyTime?: number;
    cacheKeyTime?: number;
  }[];
  e2eeVersion?: "E2EEV1" | "E2EEV2" | "E2EEV3";
  isConvergedArchitectureEnabled?: boolean;
  callingServiceType?: "CUCM" | "WEBEXCALLING" | "BROADWORKS" | "LOCUS";
  inLobby?: boolean;
  isVIPMeeting?: boolean;
  webexAppEntrypoint?: string;
  firstParticipant?: boolean;
  isImmersiveShare?: boolean;
  /**
   * Request/Response Time for Internal Services
   */
  registeredTimestamps?: {
    locusCreateConfluenceRequestTime?: string;
    locusCreateConfluenceResponseTime?: string;
    locusCreateVenueRequestTime?: string;
    locusCreateVenueResponseTime?: string;
  };
  skipInterstitialWindow?: boolean;
  callDurationSecs?: number;
  /**
   * Details associated with a breakout move
   */
  breakout?: {
    moveType?: "between_breakout" | "to_breakout" | "to_main";
    trigger?: "assignment_changed" | "client_initiated" | "session_ended" | "session_started";
    startState?: "joined" | "lobby";
    endState?: "joined" | "lobby";
  };
  /**
   * Latency values associated with breakout session
   */
  breakoutLatency?: {
    boBreakoutMoveProcessed?: number;
    boBreakoutMoveResp?: number;
    boLocusBreakoutMoveResp?: number;
    locusBreakoutMoveResp?: number;
    orpheusConfluenceMoveReqResp?: number;
  };
  /**
   * two-way whiteboard related info
   */
  whiteboard?: {
    action?: "open" | "create";
    type?: "whiteboard" | "annotation";
    capability?: "one_way" | "two_way";
    granted?: "one_way" | "two_way";
  };
  /**
   * ROAP message details
   */
  roap?: {
    type?:
      | "ANSWER"
      | "ERROR"
      | "OFFER"
      | "OFFER_REQUEST"
      | "OFFER_RESPONSE"
      | "OK"
      | "OKAY"
      | "TURN_DISCOVERY_REQUEST"
      | "TURN_DISCOVERY_RESPONSE";
    messageType?:
      | "ANSWER"
      | "ERROR"
      | "OFFER"
      | "OFFER_REQUEST"
      | "OFFER_RESPONSE"
      | "OK"
      | "OKAY"
      | "TURN_DISCOVERY_REQUEST"
      | "TURN_DISCOVERY_RESPONSE";
    error?: string;
    duration?: number;
    seq?: number;
  };
  trigger?: "dummyTrigger1" | "dummyTrigger2" | "media-quality";
  name: "server.mediaquality.event" | "client.mediaquality.event";
  /**
   * Base type for the various identifiers used to connect the dots.
   * In general, these should be populated whenever possible. Subtypes may make a particular key required.
   *
   */
  identifiers: {
    attendeeId?: string;
    breakoutGroupId?: string;
    breakoutMoveId?: string;
    breakoutSessionId?: string;
    confluenceId?: string;
    /**
     * Set of identifiers dedicated to CPaaS clients
     * In general, these should be populated whenever possible. Subtypes may make a particular key required.
     *
     */
    cpaasIdentifiers?: {
      imiTenantId: string;
      devClientId: string;
      imiServiceId: string;
      imiAppId: string;
      sessionId: string;
      sessionInstanceId: string;
    };
    csdmDeviceUrl?: string;
    destinationBreakoutSessionId?: string;
    destinationLocusSessionId?: string;
    destinationLocusUrl?: string;
    destinationVenueId?: string;
    deviceId?: string;
    ivrCallId?: string;
    ivrDialogId?: string;
    ivrId?: string;
    locusId?: string;
    locusSessionId?: string;
    locusStartTime?: string;
    locusUrl?: string;
    mediaAgentAlias?: string;
    mediaAgentGroupId?: string;
    meetClusterName?: string;
    meetingLookupUrl?: string;
    meetingOrgId?: string;
    msteamsTenantGuid?: string;
    msteamsConferenceId?: string;
    oauth2ClientId?: string;
    orgId?: string;
    provisionalCorrelationId?: string;
    roomId?: string;
    sipCallId?: string;
    sipSessionId?: {
      local?: string;
      remote?: string;
    };
    sipUri?: string;
    subConfId?: string;
    tenantId?: string;
    trackingId?: string;
    userId?: string;
    venueId?: string;
    venueUrl?: string;
    whiteboardUrl?: string;
    webexConferenceId?: number;
    webexClusterName?: string;
    webexConferenceIdStr?: string;
    webexDataCenter?: string;
    webexGuestId?: number;
    webexMeetingId?: number;
    webexNodeId?: number;
    webexSiteId?: number;
    webexSiteName?: string;
    webexUserId?: number;
    webexWebDomain?: string;
    correlationId: string;
  };
  /**
   * metadata associated with emitter of the event. This data is included only in the first emitted for a given call and does not need to be repeated with each event.
   */
  sourceMetadata?: {
    mediaEngineSoftwareType: string;
    mediaEngineSoftwareVersion: string;
    applicationSoftwareType: string;
    applicationSoftwareVersion: string;
    hardwareType?: string;
    clientRegion?: string;
    serverRegion?: string;
    serverOrg?: string;
    serverGroup?: string;
    serverAlias?: string;
    serverDeployType?: "private" | "public";
    startTime: string;
    endTime?: string;
    csi?: number[];
    isCascade?: boolean;
    isHybridMedia?: boolean;
    videoMeshClusterName?: string;
    videoMeshServerName?: string;
    isTIP?: boolean;
    isMARI?: boolean;
    has264Checksum?: boolean;
    intervalPeriod?: number;
    cascadePeerRegion?: string;
    cascadePeerOrg?: string;
    cascadePeerGroup?: string;
    cascadePeerAlias?: string;
    cascadePeerServerType?:
      | "CB"
      | "CMS"
      | "HESIOD"
      | "LINUS"
      | "MCC"
      | "MCS"
      | "MES"
      | "MJS"
      | "MRS"
      | "MYGDONUS"
      | "MZM"
      | "TERMINUS"
      | "TPGW"
      | "TA"
      | "HOMER"
      | "SUPERHOMER"
      | "U2C"
      | "WCA"
      | "MSE"
      | "UNKNOWN";
    cascadePeerDeployType?: "private" | "public";
  };
  /**
   * Details of a media edge server which is in the media path but does not generate MQE directly
   */
  edgeInfo?: {
    alias: string;
    publicIP: string;
    privateIP: string;
    version: string;
    labels?: string;
  };
  intervals: {
    intervalNumber: number;
    /**
     * The metadata associated with the emitter of the event.  This data is separate from the source metadata and must be emitted with every event.
     */
    intervalMetadata: {
      peerReflexiveIP?: string;
      maskedPeerReflexiveIP?: string;
      remoteMediaIP?: string;
      maskedRemoteMediaIP?: string;
      staticPerformanceLevel?: number;
      processAverageCPU?: number;
      processMaximumCPU?: number;
      systemAverageCPU?: number;
      systemMaximumCPU?: number;
      systemAverageGPU?: number;
      systemMaximumGPU?: number;
      /**
       * this object defines the memory related fields that are tracked in media quality events and reports
       */
      memoryUsage?: {
        processAverageMemoryUsage: number;
        processMaximumMemoryUsage: number;
        systemAverageMemoryUsage: number;
        systemMaximumMemoryUsage: number;
        processMaximumMemoryBytes: number;
        mainProcessMaximumMemoryBytes: number;
        osBitWidth: number;
        cpuBitWidth: number;
      };
      peripherals?: {
        name: "camera" | "microphone" | "speaker";
        information: string;
        driver?: string;
        errorCode?: string;
        connectionType?: unknown;
        bluetoothMode?: unknown;
      }[];
      /**
       * information object for the peripheral
       */
      cameraInfo?: {
        name: "camera" | "microphone" | "speaker";
        information: string;
        driver?: string;
        errorCode?: string;
        connectionType?: unknown;
        bluetoothMode?: unknown;
      };
      /**
       * information object for the peripheral
       */
      microphoneInfo?: {
        name: "camera" | "microphone" | "speaker";
        information: string;
        driver?: string;
        errorCode?: string;
        connectionType?: unknown;
        bluetoothMode?: unknown;
      };
      /**
       * information object for the peripheral
       */
      speakerInfo?: {
        name: "camera" | "microphone" | "speaker";
        information: string;
        driver?: string;
        errorCode?: string;
        connectionType?: unknown;
        bluetoothMode?: unknown;
      };
      /**
       * This object defines the fields related to the CPU being used by the emitter of the event
       */
      cpuInfo?: {
        description: string;
        clockSpeedGigaHertz: number;
        numberOfCores: number;
        architecture: "intel32" | "intel64" | "amd32" | "amd64" | "arm32" | "arm64" | "unknown";
        staticPerformance?: string;
      };
      /**
       * Thread level cpu performance insights
       */
      cpuDataDetail?: {
        processesData?: unknown[];
        coresCpuData?: unknown[];
        coreVariance?: number;
      };
      /**
       * This object defines the fields related to the GPU being used by the emitter of the event
       */
      defaultGpuInfo?: {
        description: string;
        memoryMegaBytes: number;
      };
      otherGpuInfo?: {
        description: string;
        memoryMegaBytes: number;
      }[];
      dpcRecord?: string[];
      mediaLabels?: string[];
      screenResolution?: number;
      screenWidth?: number;
      screenHeight?: number;
      appWindowSize?: number;
      appWindowHeight?: number;
      appWindowWidth?: number;
      meetingUserCount?: number;
      videoUserCount?: number;
      numScreens?: number;
      configuredBitrate?: number;
    };
    audioTransmit: {
      /**
       * contains the transmit related fields common between all session types for each interval
       */
      common: {
        /**
         * contains the fields common to both transmit and receive sessions for each interval
         */
        common: {
          isMain: boolean;
          mariFecEnabled: boolean;
          mariRtxEnabled?: boolean;
          mariQosEnabled: boolean;
          mariLiteEnabled?: boolean;
          multistreamEnabled: boolean;
          isMediaBypassEdge?: boolean;
          direction: "sendrecv" | "sendonly" | "recvonly" | "inactive";
          localPort?: number;
          peerReflexivePort?: number;
          remotePort?: number;
        };
        fecPackets: number;
        fecBitrate: number;
        rtxPackets?: number;
        rtxBitrate?: number;
        rtpPackets: number;
        rtpBitrate: number;
        rtcpPackets: number;
        rtcpBitrate: number;
        /**
         * RTCP Information for a given Interval
         */
        txRtcpInfo?: {
          rtcpSrPackets: number;
          rtcpRrPackets: number;
          rtcpReportBlocks: number;
          rtcpSdesPackets: number;
          rtcpByePackets: number;
          rtcpAppPackets: number;
          rtcpRtpFbPacket: number;
          rtcpPsFbPackets: number;
          rtcpPsFbMariPackets: number;
          rtcpPsFbMultistreamPackets: number;
          rtcpXrPackets: number;
        };
        stunPackets: number;
        stunBitrate: number;
        dtlsPackets: number;
        dtlsBitrate: number;
        transportType: "UDP" | "TCP" | "xTLS" | "TLS";
        maxBitrate: number;
        availableBitrate: number;
        queueDelay: number;
        meanRoundTripTime?: number;
        maxRoundTripTime?: number;
        roundTripTime: number;
        remoteReceiveRate?: number;
        maxRemoteLossRate?: number;
        remoteLossRate?: number;
        meanRemoteLossRate?: number;
        maxRemoteJitter?: number;
        remoteJitter?: number;
        meanRemoteJitter?: number;
        traversalMinDelayMs?: number;
        traversalMaxDelayMs?: number;
        traversalMeanDelayMs?: number;
        rtpInputFifoDelayMs?: number;
        rtpInputFifoMaxDelayMs?: number;
        rtpInputFifoMinDelayMs?: number;
        rtpInputFifoMeanDelayMs?: number;
      };
      streams: {
        /**
         * contains fields common to all transmit streams types
         */
        common: {
          ssci: number;
          duplicateSsci?: number;
          rtpPackets: number;
          transmittedFrameRate: number;
          requestedFrames: number;
          transmittedBitrate: number;
          requestedBitrate: number;
          captureOffset?: number;
          codec: string;
          csi?: number[];
          /**
           * This object tracks SSRC and CSRC changes for an RTP stream, session, etc
           */
          sourceChanges?: {
            /**
             * The number of RTP SSRC changes seen.  The first RTP packet seen should NOT be counted as a change.
             */
            ssrcChanges: number;
            /**
             * The number of RTP CSRC changes seen.  The first RTP packet seen should NOT be counted as a change.  Changes from zero to non-zero CSRC should be counted as a change.
             */
            csrcChanges: number;
          };
        };
        backgroundNoiseReductionMode?:
          | "AUDIO_BACKGROUND_NOISE_REDUCTION_NONE"
          | "AUDIO_BACKGROUND_NOISE_REDUCTION_HIGH_PERFORMANCE"
          | "AUDIO_BACKGROUND_NOISE_REDUCTION_LOW_POWER"
          | "AUDIO_BACKGROUND_NOISE_REDUCTION_AUTO_HIGH_PERFORMANCE"
          | "AUDIO_BACKGROUND_NOISE_REDUCTION_AUTO_LOW_POWER";
        backgroundNoiseReductionTalkerMode?:
          | "AUDIO_BACKGROUND_NOISE_REDUCTION_TALKER_NONE"
          | "AUDIO_BACKGROUND_NOISE_REDUCTION_CLASSIC_MODE"
          | "AUDIO_BACKGROUND_NOISE_REDUCTION_SINGLE_TALKER_MODE"
          | "AUDIO_BACKGROUND_NOISE_REDUCTION_MULTI_TALKER_MODE"
          | "AUDIO_BACKGROUND_NOISE_REDUCTION_MUSIC_MODE";
        audioTXSPCStatus?: "AUDIO_SPC_STATUS_DISABLED" | "AUDIO_SPC_STATUS_SUSPENDED" | "AUDIO_SPC_STATUS_ENABLED";
        audioTXSPCLevel?:
          | "AUDIO_NONE"
          | "AUDIO_LOW"
          | "AUDIO_MEDIUM"
          | "AUDIO_NORMAL"
          | "AUDIO_HIGH"
          | "AUDIO_HIGHPLUS"
          | "AUDIO_TOP";
        /**
         * audio encoder engine performance data
         */
        audioEncoderEngineInfo?: {
          /**
           * The number of audio packets sent to the encoder buffer
           */
          encoderBufferPacket?: number;
          /**
           * The number of dropped audio packets before sent to the encoder buffer
           */
          encoderBufferDroppedPacket?: number;
          /**
           * The average processing time (microseconds) on background noise reduction (BNR)
           */
          averageBNRProcessTime?: number;
          /**
           * The average processing time (microseconds) on audio encoder pipeline
           */
          averageEncoderProcessTime?: number;
        };
        /**
         * audio transmitted algorithm modules performance data(AEC,AGC,NR,MultiChannelPreprocess)
         */
        audioAlgorithmModulesInfo?: {
          /**
           * one char every 1 minute, 0 indicate 0db, plus 1 indicate -0.5dB
           */
          aecNearPower: number;
          /**
           * one char every 1 minute, 0 indicate 0db, plus 1 indicate -0.5dB
           */
          aecFarPower: number;
          /**
           * one char every 1 minute, 0 indicate 0db, plus 1 indicate -0.5dB
           */
          aecLinearOutPower?: number;
          /**
           * one char every 1 minute, 0 indicate 0db, plus 1 indicate -0.5dB
           */
          aecOutPower?: number;
          /**
           * one char every 1 minute, 0 indicate 54dB, plus 1 indicate +0.5dB
           */
          aecERLE?: number;
          /**
           * one char every 1 minute, 0 indicate 0dB, plus 1 indicate +0.5dB
           */
          aecERL?: number;
          /**
           * one char every 1 minute, 0 indicate 54dB, plus 1 indicate +0.5dB
           */
          linearAecERLE?: number;
          /**
           * one char every 1 minute, 0 indicate 0ms, plus 1 indicate 10ms
           */
          estDelay?: number;
          /**
           * one char every 1 minute
           */
          aecType?: number;
          /**
           * one unsigned short every 1 minute
           */
          aecCostTime?: number;
          /**
           * one unsigned short every 1 minute
           */
          multichannelChangedDelay?: number;
          /**
           * one unsigend char every 1 minute, 0 indicate 0db, plus 1 indicate -0.5dB
           */
          multichannelDelaySumOutPower?: number;
          /**
           * one unsigend char every 1 minute, 0 indicate 0db, plus 1 indicate -0.5dB
           */
          multichannelAverageOutPower?: number;
          /**
           * one unsigned char every 1 minute, 0 for 0dB, plus 1 for -0.5dB
           */
          speechRMS?: number;
          /**
           * one unsigned char every 1 minute, 0 for 0s, plus 4 for +1s
           */
          speechLength?: number;
          /**
           * one unsigned char every 1 minute, VAD value to reflect speech quality
           */
          speechQuality?: number;
          /**
           * one char every 1 minute.
           */
          remoteIOStatus?: number;
          /**
           * one char every 1 minute
           */
          multichannelPreprocessEnabled?: number;
          /**
           * one char every 1 minute
           */
          bypassWindowsAPOAllowListEnabled?: number;
          /**
           * one char every 1 minute, 0 for 0dB, plus 1 for 0.5dB
           */
          bnrSNR?: number;
          /**
           * one unsigned short every 1 minute
           */
          bnrTRN?: number;
          /**
           * one short every 1 minute
           */
          ftLeakage?: number;
          /**
           * one short every 1 minute
           */
          noiseLeakage?: number;
          /**
           * one short every 1 minute
           */
          echoLeakage?: number;
          /**
           * one char every 1 minute, 0 indicate 0db, plus 1 indicate 0.0472dB.
           */
          multichannelDelaySumAndDirectMixRMSRatio?: number;
          windowsAPOBypassed?: boolean;
        };
        /**
         * audio transmit pipeline modules' quality metric
         */
        audioModuleQualityInfo?: {
          /**
           * one char every 2 seconds. 0 indicate 0dB, plus 1 indicate -0.5dB
           */
          aecNearPower?: number[];
          /**
           * one char every 2 seconds. 0 indicate 0dB, plus 1 indicate -0.5dB
           */
          aecLinearOutPower?: number[];
          /**
           * one char every 2 seconds. 0 indicate 0dB, plus 1 indicate -0.5dB
           */
          aecOutPower?: number[];
          /**
           * one char every 2 seconds. 0 indicate 0dB, plus 1 indicate -0.5dB
           */
          aecFarPower?: number[];
          /**
           * One char every 2 seconds.
           */
          aecStatus?: number[];
          /**
           * one char every 2 seconds.
           */
          bblOutPower?: number[];
          /**
           * one char every 2 seconds
           */
          volumeAndDelay?: number[];
          /**
           * one char every 2 seconds. 0 indicate 0dB, plus 1 indicate -0.5dB
           */
          agcOutPower?: number[];
          /**
           * one char every 2 seconds. 0 indicate 0dB, plus 1 indicate -0.5dB
           */
          agcAvgOutPower?: number[];
          /**
           * one char every 2 seconds. 0 indicate 0dB, plus 1 indicate -0.5dB
           */
          agcAvgInputPower?: number[];
          /**
           * one char every 1 minute.
           */
          agcType?: number;
        };
        audioCaptureMethod?: "AUDIO_ANDROID_JAVA_METHOD" | "AUDIO_ANDROID_AAUDIO_METHOD";
      }[];
      /**
       * information about tracked audio levels
       */
      levels?: {
        /**
         * The average audio input gain for a microphone or speaker, in decibels
         */
        audioMeanGain?: number;
        /**
         * The minimum audio input gain for a microphone or speaker, in decibels
         */
        audioMinGain?: number;
        /**
         * The maximum audio input gain for a microphone or speaker, in decibels
         */
        audioMaxGain?: number;
        /**
         * The mean audio output volume for a microphone or speaker, in absolute volume [0-65535]
         */
        audioMeanVolume?: number;
        /**
         * The min audio output volume for a microphone or speaker, in absolute volume [0-65535]
         */
        audioMinVolume?: number;
        /**
         * The max audio output volume for a microphone or speaker, in absolute volume [0-65535]
         */
        audioMaxVolume?: number;
      };
      captureHardwareProvidedAudioPacketsPerSecond?: number;
      sharedAudioPacketsPerSecond?: number;
    }[];
    videoTransmit: {
      /**
       * contains the transmit related fields common between all session types for each interval
       */
      common: {
        /**
         * contains the fields common to both transmit and receive sessions for each interval
         */
        common: {
          isMain: boolean;
          mariFecEnabled: boolean;
          mariRtxEnabled?: boolean;
          mariQosEnabled: boolean;
          mariLiteEnabled?: boolean;
          multistreamEnabled: boolean;
          isMediaBypassEdge?: boolean;
          direction: "sendrecv" | "sendonly" | "recvonly" | "inactive";
          localPort?: number;
          peerReflexivePort?: number;
          remotePort?: number;
        };
        fecPackets: number;
        fecBitrate: number;
        rtxPackets?: number;
        rtxBitrate?: number;
        rtpPackets: number;
        rtpBitrate: number;
        rtcpPackets: number;
        rtcpBitrate: number;
        /**
         * RTCP Information for a given Interval
         */
        txRtcpInfo?: {
          rtcpSrPackets: number;
          rtcpRrPackets: number;
          rtcpReportBlocks: number;
          rtcpSdesPackets: number;
          rtcpByePackets: number;
          rtcpAppPackets: number;
          rtcpRtpFbPacket: number;
          rtcpPsFbPackets: number;
          rtcpPsFbMariPackets: number;
          rtcpPsFbMultistreamPackets: number;
          rtcpXrPackets: number;
        };
        stunPackets: number;
        stunBitrate: number;
        dtlsPackets: number;
        dtlsBitrate: number;
        transportType: "UDP" | "TCP" | "xTLS" | "TLS";
        maxBitrate: number;
        availableBitrate: number;
        queueDelay: number;
        meanRoundTripTime?: number;
        maxRoundTripTime?: number;
        roundTripTime: number;
        remoteReceiveRate?: number;
        maxRemoteLossRate?: number;
        remoteLossRate?: number;
        meanRemoteLossRate?: number;
        maxRemoteJitter?: number;
        remoteJitter?: number;
        meanRemoteJitter?: number;
        traversalMinDelayMs?: number;
        traversalMaxDelayMs?: number;
        traversalMeanDelayMs?: number;
        rtpInputFifoDelayMs?: number;
        rtpInputFifoMaxDelayMs?: number;
        rtpInputFifoMinDelayMs?: number;
        rtpInputFifoMeanDelayMs?: number;
      };
      streams: {
        /**
         * contains fields common to all transmit streams types
         */
        common: {
          ssci: number;
          duplicateSsci?: number;
          rtpPackets: number;
          transmittedFrameRate: number;
          requestedFrames: number;
          transmittedBitrate: number;
          requestedBitrate: number;
          captureOffset?: number;
          codec: string;
          csi?: number[];
          /**
           * This object tracks SSRC and CSRC changes for an RTP stream, session, etc
           */
          sourceChanges?: {
            /**
             * The number of RTP SSRC changes seen.  The first RTP packet seen should NOT be counted as a change.
             */
            ssrcChanges: number;
            /**
             * The number of RTP CSRC changes seen.  The first RTP packet seen should NOT be counted as a change.  Changes from zero to non-zero CSRC should be counted as a change.
             */
            csrcChanges: number;
          };
        };
        transmittedFrameSize: number;
        requestedFrameSize: number;
        transmittedHeight: number;
        transmittedWidth: number;
        transmittedKeyFrames: number;
        requestedKeyFrames: number;
        transmittedKeyFramesFeedback?: number;
        transmittedKeyFramesConfigurationChange?: number;
        transmittedKeyFramesSceneChange?: number;
        transmittedKeyFramesOtherLayer?: number;
        transmittedKeyFramesClient?: number;
        transmittedKeyFramesPeriodic?: number;
        transmittedKeyFramesLocalDrop?: number;
        transmittedKeyFramesStartup?: number;
        transmittedKeyFramesUnknown?: number;
        transmittedKeyFramesEncLayerIndexChange?: number;
        transmittedKeyFramesSwitchingPoint?: number;
        localConfigurationChanges: number;
        remoteConfigurationChanges: number;
        h264CodecProfile: "BP" | "CHP";
        isAvatar?: boolean;
        /**
         * video encode quality metrics
         */
        encodeQuality?: {
          minRegionQp: number;
          maxFrameQp: number;
          maxNoiseLevel: number;
        };
        /**
         * video transmit downgrade reasons
         */
        downgradeReason?: {
          isCamera: boolean;
          isNetwork: boolean;
          isCpu: boolean;
          isRequested?: boolean;
          isUser?: boolean;
          isHardware?: boolean;
        };
        isHardwareEncoded?: boolean;
        backgroundAugmentationType?:
          | "VIDEO_BACKGROUND_AUGMENT_NONE"
          | "VIDEO_BACKGROUND_AUGMENT_BLUR"
          | "VIDEO_BACKGROUND_AUGMENT_REPLACE_IMAGE"
          | "VIDEO_BACKGROUND_AUGMENT_REPLACE_VIDEO"
          | "VIDEO_BACKGROUND_AUGMENT_BLUR_INHOUSE"
          | "VIDEO_BACKGROUND_AUGMENT_REPLACE_IMAGE_INHOUSE"
          | "VIDEO_BACKGROUND_AUGMENT_REPLACE_VIDEO_INHOUSE";
        backgroundAugmentationFrameworkType?:
          | "VIDEO_VBG_FRAMEWORK_NONE"
          | "VIDEO_VBG_FRAMEWORK_COREML"
          | "VIDEO_VBG_FRAMEWORK_METAL"
          | "VIDEO_VBG_FRAMEWORK_CBASED"
          | "VIDEO_VBG_FRAMEWORK_OPENVINO"
          | "VIDEO_VBG_FRAMEWORK_COREML_LADON"
          | "VIDEO_VBG_FRAMEWORK_METAL_LADON"
          | "VIDEO_VBG_FRAMEWORK_CBASED_LADON"
          | "VIDEO_VBG_FRAMEWORK_OPENVINO_LADON";
        /**
         * transmit video pipeline performance metric
         */
        encoderProcessInfo?: {
          meanEncoderProcessMillis: number;
          maxEncoderProcessMillis: number;
          meanVbgProcessMillis?: number;
          maxVbgProcessMillis?: number;
        };
        backgroundAugmentationModelVersion?: string;
        isGestureDetectorOn?: boolean;
        capturedFrameRateNormalShare?: number;
        capturedFrameRateHFPSShare?: number;
        transmittedFrameRateNormalShare?: number;
        transmittedFrameRateHFPSShare?: number;
        /**
         * the method use to capture the screen for screen sharing
         */
        screenCaptureMode?:
          | "Unknown"
          | "Default"
          | "MAG"
          | "DUP"
          | "AVF"
          | "CGS"
          | "GDI"
          | "DIRECTX"
          | "WINDOW"
          | "SCK";
        processShareContentDetectMillis?: number;
      }[];
    }[];
    audioReceive: {
      /**
       * contains the receive related fields between all sessions types for each interval.
       */
      common: {
        /**
         * contains the fields common to both transmit and receive sessions for each interval
         */
        common: {
          isMain: boolean;
          mariFecEnabled: boolean;
          mariRtxEnabled?: boolean;
          mariQosEnabled: boolean;
          mariLiteEnabled?: boolean;
          multistreamEnabled: boolean;
          isMediaBypassEdge?: boolean;
          direction: "sendrecv" | "sendonly" | "recvonly" | "inactive";
          localPort?: number;
          peerReflexivePort?: number;
          remotePort?: number;
        };
        fecPackets: number;
        fecBitrate: number;
        rtxPackets?: number;
        rtxBitrate?: number;
        meanRtxDelay?: number;
        maxRtxDelay?: number;
        rtpPackets: number;
        rtpBitrate: number;
        rtpHopByHopLost: number;
        mediaHopByHopLost: number;
        rtpRecovered: number;
        rtxRecovered?: number;
        rtcpPackets: number;
        rtcpBitrate: number;
        /**
         * RTCP Information for a given Interval
         */
        rxRtcpInfo?: {
          rtcpSrPackets: number;
          rtcpRrPackets: number;
          rtcpReportBlocks: number;
          rtcpSdesPackets: number;
          rtcpByePackets: number;
          rtcpAppPackets: number;
          rtcpRtpFbPacket: number;
          rtcpPsFbPackets: number;
          rtcpPsFbMariPackets: number;
          rtcpPsFbMultistreamPackets: number;
          rtcpXrPackets: number;
        };
        stunPackets: number;
        stunBitrate: number;
        dtlsPackets: number;
        dtlsBitrate: number;
        transportType: "UDP" | "TCP" | "xTLS" | "TLS";
        maxBitrate: number;
        srtpUnprotectErrors: number;
        /**
         * SRTP/SRTCP unprotect error details
         */
        srtpUnprotectErrorDetails?: {
          authFailures: number;
          cipherFailures: number;
          replayFailures: number;
          unknownFailures: number;
        };
        srtcpUnprotectErrors: number;
        /**
         * SRTP/SRTCP unprotect error details
         */
        srtcpUnprotectErrorDetails?: {
          authFailures: number;
          cipherFailures: number;
          replayFailures: number;
          unknownFailures: number;
        };
      };
      streams: {
        /**
         * contains fields common to all types of receive stream
         */
        common: {
          ssci: number;
          rtpPackets: number;
          rtpEndToEndLost: number;
          concealedFrames: number;
          maxConcealRunLength: number;
          receivedFrameRate: number;
          renderedFrameRate: number;
          requestedFrameRate: number;
          optimalFrameRate: number;
          meanRtpJitter?: number;
          maxRtpJitter?: number;
          rtpJitter?: number;
          receivedBitrate: number;
          requestedBitrate: number;
          optimalBitrate: number;
          durationForSpeedChanged?: number;
          endToEndTransmitDelay?: number;
          csi: number[];
          codec: string;
          /**
           * This object tracks SSRC and CSRC changes for an RTP stream, session, etc
           */
          sourceChanges?: {
            /**
             * The number of RTP SSRC changes seen.  The first RTP packet seen should NOT be counted as a change.
             */
            ssrcChanges: number;
            /**
             * The number of RTP CSRC changes seen.  The first RTP packet seen should NOT be counted as a change.  Changes from zero to non-zero CSRC should be counted as a change.
             */
            csrcChanges: number;
          };
          /**
           * The object tracks the detail reasons by which concealment is caused. The unit of metrics depend on upper-level objects. Currently, packet or frame can be used as unit.
           */
          concealmentReasonByPacket?: {
            /**
             * concealment caused by network loss
             */
            byNetwork?: number;
            /**
             * concealment caused by buffer overflow. when total buffer length exceeds max delay threshold, buffer will overflow and data will be dropped.
             */
            byOverflow?: number;
            /**
             * concealment caused by buffer is reset.
             */
            byReset?: number;
            /**
             * concealment caused by late packet or frame. some packets or frames arrive late and the previous one has been played.
             */
            byLate?: number;
            /**
             * concealment caused by poor performance.
             */
            byPoorPerformance?: number;
            /**
             * only for audio. Number of concealment packets/frames sent to the audio decoder when frames are held back to increase re-order audio delay.
             */
            byIncreasedDelay?: number;
            /**
             * only for video. concealment caused by AV sync
             */
            byAVSync?: number;
            /**
             * only for video. Some video frames which have not been complete are forced to pop up because the subsequent frame has been complete. This cause video concealment.
             */
            byPrevFramePopped?: number;
            /**
             * concealment caused by the other unknown reasons
             */
            byOthers?: number;
          };
          /**
           * The object tracks the detail reasons by which concealment is caused. The unit of metrics depend on upper-level objects. Currently, packet or frame can be used as unit.
           */
          concealmentReasonByFrame?: {
            /**
             * concealment caused by network loss
             */
            byNetwork?: number;
            /**
             * concealment caused by buffer overflow. when total buffer length exceeds max delay threshold, buffer will overflow and data will be dropped.
             */
            byOverflow?: number;
            /**
             * concealment caused by buffer is reset.
             */
            byReset?: number;
            /**
             * concealment caused by late packet or frame. some packets or frames arrive late and the previous one has been played.
             */
            byLate?: number;
            /**
             * concealment caused by poor performance.
             */
            byPoorPerformance?: number;
            /**
             * only for audio. Number of concealment packets/frames sent to the audio decoder when frames are held back to increase re-order audio delay.
             */
            byIncreasedDelay?: number;
            /**
             * only for video. concealment caused by AV sync
             */
            byAVSync?: number;
            /**
             * only for video. Some video frames which have not been complete are forced to pop up because the subsequent frame has been complete. This cause video concealment.
             */
            byPrevFramePopped?: number;
            /**
             * concealment caused by the other unknown reasons
             */
            byOthers?: number;
          };
          /**
           * the number of  consecutive concealment time which is larger than the threshold in one minute.  Currently,  60 and 120 ms are used as the threshold.
           */
          interruptCount?: {
            /**
             * interrupt count longer than 60 ms in one minute
             */
            longerThan60?: number;
            /**
             * interrupt count longer than 120 ms in one minute
             */
            longerThan120?: number;
          };
          /**
           * This object tracks the delay associated with a jitter buffer
           */
          jitterBufferDelay?: {
            /**
             * The average delay (in milliseconds) used by the jitter buffer
             */
            meanDelay: number;
            /**
             * The maximum delay (in milliseconds) used by the jitter buffer
             */
            maxDelay: number;
            /**
             * The minimum delay (in milliseconds) used by the jitter buffer
             */
            minDelay: number;
          };
          /**
           * This object tracks the the end to end delay(the delay between capture time of sender side and render time of receiver side)
           */
          endToEndDelay?: {
            /**
             * The average delay (in milliseconds) from end to end
             */
            meanDelay: number;
            /**
             * The maximum delay (in milliseconds) from end to end
             */
            maxDelay: number;
            /**
             * The minimum delay (in milliseconds) from end to end
             */
            minDelay: number;
          };
          /**
           * Aggregated end to end delay representing the mean, max, min delay group by csi
           */
          endToEndDelayByCsi?: {
            csi?: number;
            delay?: unknown;
          }[];
        };
        isRxCallBackgroundNoiseReductionModeOn?: boolean;
        isMeasureSNROn?: boolean;
        averageSNRValue?: number;
        /**
         * contains fields for QOEM MOS score
         */
        audioqoem?: {
          version: string;
          /**
           * Average Estimated Mean Opinion Score by considering networks jitter, loss etc.
           */
          averageNetMOS: number;
          /**
           * Min Estimated Mean Opinion score by considering networks jitter, loss etc.
           */
          minNetMOS: number;
          /**
           * Average Estimated Mean Opinion Score jitter buffers status, such as drop packet, do PLC, do recover etc.
           */
          averageJitterMOS: number;
          /**
           * Min Estimated Mean Opinion Score jitter buffers status, such as drop packet, do PLC, do recover etc.
           */
          minJitterMOS: number;
          /**
           * Perceptual Evaluation of Speech Quality - Listening Quality Objective (PESQ-LQO)
           */
          pesqLQO?: number;
        };
        audioPlaybackMethod?: "AUDIO_ANDROID_JAVA_METHOD" | "AUDIO_ANDROID_AAUDIO_METHOD";
        /**
         * audio received algorithm modules performance data(AGC,NR,MultiChannelPreprocess)
         */
        audioAlgorithmModulesInfo?: {
          /**
           * one unsigned char every 1 minute, 0 for 0dB, plus 1 for -0.5dB
           */
          speechRMS?: number;
          /**
           * one unsigned char every 1 minute, 0 for 0s, plus 4 for +1s
           */
          speechLength?: number;
          /**
           * one unsigned char every 1 minute, VAD value to reflect speech quality
           */
          speechQuality?: number;
          /**
           * one unsigned short every 1 minute
           */
          bnrTRN?: number;
        };
        /**
         * audio receive pipeline modules' quality metric
         */
        audioModuleQualityInfo?: {
          /**
           * one char every 2 seconds. 0 indicate 0dB, plus 1 indicate -0.5dB
           */
          agcOutPower?: number[];
          /**
           * one char every 2 seconds. 0 indicate 0dB, plus 1 indicate -0.5dB
           */
          agcAvgOutPower?: number[];
        };
        /**
         * This object tracks the the audio video sync data, to see whether the video timestamp is matching with audio timestamp
         */
        avSync?: {
          /**
           * Compared with audio, the maximum video delay time (in milliseconds) in last interval
           */
          maxVideoLateInterval?: number;
          /**
           * Compared with audio, the maximum video early time (in milliseconds) in last interval
           */
          maxVideoEarlyInterval?: number;
          /**
           * Compared with audio, the unsync video frames get played out / total frames
           */
          decidePlayedUnsyncRatio?: number;
        };
      }[];
      /**
       * information about tracked audio levels
       */
      levels?: {
        /**
         * The average audio input gain for a microphone or speaker, in decibels
         */
        audioMeanGain?: number;
        /**
         * The minimum audio input gain for a microphone or speaker, in decibels
         */
        audioMinGain?: number;
        /**
         * The maximum audio input gain for a microphone or speaker, in decibels
         */
        audioMaxGain?: number;
        /**
         * The mean audio output volume for a microphone or speaker, in absolute volume [0-65535]
         */
        audioMeanVolume?: number;
        /**
         * The min audio output volume for a microphone or speaker, in absolute volume [0-65535]
         */
        audioMinVolume?: number;
        /**
         * The max audio output volume for a microphone or speaker, in absolute volume [0-65535]
         */
        audioMaxVolume?: number;
      };
      playbackHardwareRequiredAudioPacketsPerSecond?: number;
    }[];
    videoReceive: {
      /**
       * contains the receive related fields between all sessions types for each interval.
       */
      common: {
        /**
         * contains the fields common to both transmit and receive sessions for each interval
         */
        common: {
          isMain: boolean;
          mariFecEnabled: boolean;
          mariRtxEnabled?: boolean;
          mariQosEnabled: boolean;
          mariLiteEnabled?: boolean;
          multistreamEnabled: boolean;
          isMediaBypassEdge?: boolean;
          direction: "sendrecv" | "sendonly" | "recvonly" | "inactive";
          localPort?: number;
          peerReflexivePort?: number;
          remotePort?: number;
        };
        fecPackets: number;
        fecBitrate: number;
        rtxPackets?: number;
        rtxBitrate?: number;
        meanRtxDelay?: number;
        maxRtxDelay?: number;
        rtpPackets: number;
        rtpBitrate: number;
        rtpHopByHopLost: number;
        mediaHopByHopLost: number;
        rtpRecovered: number;
        rtxRecovered?: number;
        rtcpPackets: number;
        rtcpBitrate: number;
        /**
         * RTCP Information for a given Interval
         */
        rxRtcpInfo?: {
          rtcpSrPackets: number;
          rtcpRrPackets: number;
          rtcpReportBlocks: number;
          rtcpSdesPackets: number;
          rtcpByePackets: number;
          rtcpAppPackets: number;
          rtcpRtpFbPacket: number;
          rtcpPsFbPackets: number;
          rtcpPsFbMariPackets: number;
          rtcpPsFbMultistreamPackets: number;
          rtcpXrPackets: number;
        };
        stunPackets: number;
        stunBitrate: number;
        dtlsPackets: number;
        dtlsBitrate: number;
        transportType: "UDP" | "TCP" | "xTLS" | "TLS";
        maxBitrate: number;
        srtpUnprotectErrors: number;
        /**
         * SRTP/SRTCP unprotect error details
         */
        srtpUnprotectErrorDetails?: {
          authFailures: number;
          cipherFailures: number;
          replayFailures: number;
          unknownFailures: number;
        };
        srtcpUnprotectErrors: number;
        /**
         * SRTP/SRTCP unprotect error details
         */
        srtcpUnprotectErrorDetails?: {
          authFailures: number;
          cipherFailures: number;
          replayFailures: number;
          unknownFailures: number;
        };
      };
      streams: {
        /**
         * contains fields common to all types of receive stream
         */
        common: {
          ssci: number;
          rtpPackets: number;
          rtpEndToEndLost: number;
          concealedFrames: number;
          maxConcealRunLength: number;
          receivedFrameRate: number;
          renderedFrameRate: number;
          requestedFrameRate: number;
          optimalFrameRate: number;
          meanRtpJitter?: number;
          maxRtpJitter?: number;
          rtpJitter?: number;
          receivedBitrate: number;
          requestedBitrate: number;
          optimalBitrate: number;
          durationForSpeedChanged?: number;
          endToEndTransmitDelay?: number;
          csi: number[];
          codec: string;
          /**
           * This object tracks SSRC and CSRC changes for an RTP stream, session, etc
           */
          sourceChanges?: {
            /**
             * The number of RTP SSRC changes seen.  The first RTP packet seen should NOT be counted as a change.
             */
            ssrcChanges: number;
            /**
             * The number of RTP CSRC changes seen.  The first RTP packet seen should NOT be counted as a change.  Changes from zero to non-zero CSRC should be counted as a change.
             */
            csrcChanges: number;
          };
          /**
           * The object tracks the detail reasons by which concealment is caused. The unit of metrics depend on upper-level objects. Currently, packet or frame can be used as unit.
           */
          concealmentReasonByPacket?: {
            /**
             * concealment caused by network loss
             */
            byNetwork?: number;
            /**
             * concealment caused by buffer overflow. when total buffer length exceeds max delay threshold, buffer will overflow and data will be dropped.
             */
            byOverflow?: number;
            /**
             * concealment caused by buffer is reset.
             */
            byReset?: number;
            /**
             * concealment caused by late packet or frame. some packets or frames arrive late and the previous one has been played.
             */
            byLate?: number;
            /**
             * concealment caused by poor performance.
             */
            byPoorPerformance?: number;
            /**
             * only for audio. Number of concealment packets/frames sent to the audio decoder when frames are held back to increase re-order audio delay.
             */
            byIncreasedDelay?: number;
            /**
             * only for video. concealment caused by AV sync
             */
            byAVSync?: number;
            /**
             * only for video. Some video frames which have not been complete are forced to pop up because the subsequent frame has been complete. This cause video concealment.
             */
            byPrevFramePopped?: number;
            /**
             * concealment caused by the other unknown reasons
             */
            byOthers?: number;
          };
          /**
           * The object tracks the detail reasons by which concealment is caused. The unit of metrics depend on upper-level objects. Currently, packet or frame can be used as unit.
           */
          concealmentReasonByFrame?: {
            /**
             * concealment caused by network loss
             */
            byNetwork?: number;
            /**
             * concealment caused by buffer overflow. when total buffer length exceeds max delay threshold, buffer will overflow and data will be dropped.
             */
            byOverflow?: number;
            /**
             * concealment caused by buffer is reset.
             */
            byReset?: number;
            /**
             * concealment caused by late packet or frame. some packets or frames arrive late and the previous one has been played.
             */
            byLate?: number;
            /**
             * concealment caused by poor performance.
             */
            byPoorPerformance?: number;
            /**
             * only for audio. Number of concealment packets/frames sent to the audio decoder when frames are held back to increase re-order audio delay.
             */
            byIncreasedDelay?: number;
            /**
             * only for video. concealment caused by AV sync
             */
            byAVSync?: number;
            /**
             * only for video. Some video frames which have not been complete are forced to pop up because the subsequent frame has been complete. This cause video concealment.
             */
            byPrevFramePopped?: number;
            /**
             * concealment caused by the other unknown reasons
             */
            byOthers?: number;
          };
          /**
           * the number of  consecutive concealment time which is larger than the threshold in one minute.  Currently,  60 and 120 ms are used as the threshold.
           */
          interruptCount?: {
            /**
             * interrupt count longer than 60 ms in one minute
             */
            longerThan60?: number;
            /**
             * interrupt count longer than 120 ms in one minute
             */
            longerThan120?: number;
          };
          /**
           * This object tracks the delay associated with a jitter buffer
           */
          jitterBufferDelay?: {
            /**
             * The average delay (in milliseconds) used by the jitter buffer
             */
            meanDelay: number;
            /**
             * The maximum delay (in milliseconds) used by the jitter buffer
             */
            maxDelay: number;
            /**
             * The minimum delay (in milliseconds) used by the jitter buffer
             */
            minDelay: number;
          };
          /**
           * This object tracks the the end to end delay(the delay between capture time of sender side and render time of receiver side)
           */
          endToEndDelay?: {
            /**
             * The average delay (in milliseconds) from end to end
             */
            meanDelay: number;
            /**
             * The maximum delay (in milliseconds) from end to end
             */
            maxDelay: number;
            /**
             * The minimum delay (in milliseconds) from end to end
             */
            minDelay: number;
          };
          /**
           * Aggregated end to end delay representing the mean, max, min delay group by csi
           */
          endToEndDelayByCsi?: {
            csi?: number;
            delay?: unknown;
          }[];
        };
        receivedFrameSize: number;
        requestedFrameSize: number;
        optimalFrameSize: number;
        receivedHeight: number;
        receivedWidth: number;
        receivedKeyFrames: number;
        requestedKeyFrames: number;
        receivedKeyFramesSourceChange?: number;
        receivedKeyFramesConfigurationChange?: number;
        receivedKeyFramesForRequest?: number;
        receivedKeyFramesUnknown?: number;
        isActiveSpeaker?: boolean;
        h264CodecProfile: "BP" | "CHP";
        isHardwareDecoded?: boolean;
        /**
         * receive video pipeline performance metric
         */
        decoderProcessInfo?: {
          meanDecoderProcessMillis: number;
          maxDecoderProcessMillis: number;
        };
        receivedBuffer?: number;
        receivedFrameRateNormalShare?: number;
        receivedFrameRateHFPSShare?: number;
        renderWindowResolution?: number;
        scaledResolution?: number;
      }[];
    }[];
    gamestateTransmit?: {
      /**
       * contains the transmit related fields common between all session types for each interval
       */
      common: {
        /**
         * contains the fields common to both transmit and receive sessions for each interval
         */
        common: {
          isMain: boolean;
          mariFecEnabled: boolean;
          mariRtxEnabled?: boolean;
          mariQosEnabled: boolean;
          mariLiteEnabled?: boolean;
          multistreamEnabled: boolean;
          isMediaBypassEdge?: boolean;
          direction: "sendrecv" | "sendonly" | "recvonly" | "inactive";
          localPort?: number;
          peerReflexivePort?: number;
          remotePort?: number;
        };
        fecPackets: number;
        fecBitrate: number;
        rtxPackets?: number;
        rtxBitrate?: number;
        rtpPackets: number;
        rtpBitrate: number;
        rtcpPackets: number;
        rtcpBitrate: number;
        /**
         * RTCP Information for a given Interval
         */
        txRtcpInfo?: {
          rtcpSrPackets: number;
          rtcpRrPackets: number;
          rtcpReportBlocks: number;
          rtcpSdesPackets: number;
          rtcpByePackets: number;
          rtcpAppPackets: number;
          rtcpRtpFbPacket: number;
          rtcpPsFbPackets: number;
          rtcpPsFbMariPackets: number;
          rtcpPsFbMultistreamPackets: number;
          rtcpXrPackets: number;
        };
        stunPackets: number;
        stunBitrate: number;
        dtlsPackets: number;
        dtlsBitrate: number;
        transportType: "UDP" | "TCP" | "xTLS" | "TLS";
        maxBitrate: number;
        availableBitrate: number;
        queueDelay: number;
        meanRoundTripTime?: number;
        maxRoundTripTime?: number;
        roundTripTime: number;
        remoteReceiveRate?: number;
        maxRemoteLossRate?: number;
        remoteLossRate?: number;
        meanRemoteLossRate?: number;
        maxRemoteJitter?: number;
        remoteJitter?: number;
        meanRemoteJitter?: number;
        traversalMinDelayMs?: number;
        traversalMaxDelayMs?: number;
        traversalMeanDelayMs?: number;
        rtpInputFifoDelayMs?: number;
        rtpInputFifoMaxDelayMs?: number;
        rtpInputFifoMinDelayMs?: number;
        rtpInputFifoMeanDelayMs?: number;
      };
      streams: {
        /**
         * contains fields common to all transmit streams types
         */
        common: {
          ssci: number;
          duplicateSsci?: number;
          rtpPackets: number;
          transmittedFrameRate: number;
          requestedFrames: number;
          transmittedBitrate: number;
          requestedBitrate: number;
          captureOffset?: number;
          codec: string;
          csi?: number[];
          /**
           * This object tracks SSRC and CSRC changes for an RTP stream, session, etc
           */
          sourceChanges?: {
            /**
             * The number of RTP SSRC changes seen.  The first RTP packet seen should NOT be counted as a change.
             */
            ssrcChanges: number;
            /**
             * The number of RTP CSRC changes seen.  The first RTP packet seen should NOT be counted as a change.  Changes from zero to non-zero CSRC should be counted as a change.
             */
            csrcChanges: number;
          };
        };
        gamestateObjects?: {
          objectId: number;
          numberOfUpdates: number;
          tag: unknown;
          isActive: boolean;
        }[];
      }[];
    }[];
    gamestateReceive?: {
      /**
       * contains the receive related fields between all sessions types for each interval.
       */
      common: {
        /**
         * contains the fields common to both transmit and receive sessions for each interval
         */
        common: {
          isMain: boolean;
          mariFecEnabled: boolean;
          mariRtxEnabled?: boolean;
          mariQosEnabled: boolean;
          mariLiteEnabled?: boolean;
          multistreamEnabled: boolean;
          isMediaBypassEdge?: boolean;
          direction: "sendrecv" | "sendonly" | "recvonly" | "inactive";
          localPort?: number;
          peerReflexivePort?: number;
          remotePort?: number;
        };
        fecPackets: number;
        fecBitrate: number;
        rtxPackets?: number;
        rtxBitrate?: number;
        meanRtxDelay?: number;
        maxRtxDelay?: number;
        rtpPackets: number;
        rtpBitrate: number;
        rtpHopByHopLost: number;
        mediaHopByHopLost: number;
        rtpRecovered: number;
        rtxRecovered?: number;
        rtcpPackets: number;
        rtcpBitrate: number;
        /**
         * RTCP Information for a given Interval
         */
        rxRtcpInfo?: {
          rtcpSrPackets: number;
          rtcpRrPackets: number;
          rtcpReportBlocks: number;
          rtcpSdesPackets: number;
          rtcpByePackets: number;
          rtcpAppPackets: number;
          rtcpRtpFbPacket: number;
          rtcpPsFbPackets: number;
          rtcpPsFbMariPackets: number;
          rtcpPsFbMultistreamPackets: number;
          rtcpXrPackets: number;
        };
        stunPackets: number;
        stunBitrate: number;
        dtlsPackets: number;
        dtlsBitrate: number;
        transportType: "UDP" | "TCP" | "xTLS" | "TLS";
        maxBitrate: number;
        srtpUnprotectErrors: number;
        /**
         * SRTP/SRTCP unprotect error details
         */
        srtpUnprotectErrorDetails?: {
          authFailures: number;
          cipherFailures: number;
          replayFailures: number;
          unknownFailures: number;
        };
        srtcpUnprotectErrors: number;
        /**
         * SRTP/SRTCP unprotect error details
         */
        srtcpUnprotectErrorDetails?: {
          authFailures: number;
          cipherFailures: number;
          replayFailures: number;
          unknownFailures: number;
        };
      };
      streams: {
        /**
         * contains fields common to all types of receive stream
         */
        common: {
          ssci: number;
          rtpPackets: number;
          rtpEndToEndLost: number;
          concealedFrames: number;
          maxConcealRunLength: number;
          receivedFrameRate: number;
          renderedFrameRate: number;
          requestedFrameRate: number;
          optimalFrameRate: number;
          meanRtpJitter?: number;
          maxRtpJitter?: number;
          rtpJitter?: number;
          receivedBitrate: number;
          requestedBitrate: number;
          optimalBitrate: number;
          durationForSpeedChanged?: number;
          endToEndTransmitDelay?: number;
          csi: number[];
          codec: string;
          /**
           * This object tracks SSRC and CSRC changes for an RTP stream, session, etc
           */
          sourceChanges?: {
            /**
             * The number of RTP SSRC changes seen.  The first RTP packet seen should NOT be counted as a change.
             */
            ssrcChanges: number;
            /**
             * The number of RTP CSRC changes seen.  The first RTP packet seen should NOT be counted as a change.  Changes from zero to non-zero CSRC should be counted as a change.
             */
            csrcChanges: number;
          };
          /**
           * The object tracks the detail reasons by which concealment is caused. The unit of metrics depend on upper-level objects. Currently, packet or frame can be used as unit.
           */
          concealmentReasonByPacket?: {
            /**
             * concealment caused by network loss
             */
            byNetwork?: number;
            /**
             * concealment caused by buffer overflow. when total buffer length exceeds max delay threshold, buffer will overflow and data will be dropped.
             */
            byOverflow?: number;
            /**
             * concealment caused by buffer is reset.
             */
            byReset?: number;
            /**
             * concealment caused by late packet or frame. some packets or frames arrive late and the previous one has been played.
             */
            byLate?: number;
            /**
             * concealment caused by poor performance.
             */
            byPoorPerformance?: number;
            /**
             * only for audio. Number of concealment packets/frames sent to the audio decoder when frames are held back to increase re-order audio delay.
             */
            byIncreasedDelay?: number;
            /**
             * only for video. concealment caused by AV sync
             */
            byAVSync?: number;
            /**
             * only for video. Some video frames which have not been complete are forced to pop up because the subsequent frame has been complete. This cause video concealment.
             */
            byPrevFramePopped?: number;
            /**
             * concealment caused by the other unknown reasons
             */
            byOthers?: number;
          };
          /**
           * The object tracks the detail reasons by which concealment is caused. The unit of metrics depend on upper-level objects. Currently, packet or frame can be used as unit.
           */
          concealmentReasonByFrame?: {
            /**
             * concealment caused by network loss
             */
            byNetwork?: number;
            /**
             * concealment caused by buffer overflow. when total buffer length exceeds max delay threshold, buffer will overflow and data will be dropped.
             */
            byOverflow?: number;
            /**
             * concealment caused by buffer is reset.
             */
            byReset?: number;
            /**
             * concealment caused by late packet or frame. some packets or frames arrive late and the previous one has been played.
             */
            byLate?: number;
            /**
             * concealment caused by poor performance.
             */
            byPoorPerformance?: number;
            /**
             * only for audio. Number of concealment packets/frames sent to the audio decoder when frames are held back to increase re-order audio delay.
             */
            byIncreasedDelay?: number;
            /**
             * only for video. concealment caused by AV sync
             */
            byAVSync?: number;
            /**
             * only for video. Some video frames which have not been complete are forced to pop up because the subsequent frame has been complete. This cause video concealment.
             */
            byPrevFramePopped?: number;
            /**
             * concealment caused by the other unknown reasons
             */
            byOthers?: number;
          };
          /**
           * the number of  consecutive concealment time which is larger than the threshold in one minute.  Currently,  60 and 120 ms are used as the threshold.
           */
          interruptCount?: {
            /**
             * interrupt count longer than 60 ms in one minute
             */
            longerThan60?: number;
            /**
             * interrupt count longer than 120 ms in one minute
             */
            longerThan120?: number;
          };
          /**
           * This object tracks the delay associated with a jitter buffer
           */
          jitterBufferDelay?: {
            /**
             * The average delay (in milliseconds) used by the jitter buffer
             */
            meanDelay: number;
            /**
             * The maximum delay (in milliseconds) used by the jitter buffer
             */
            maxDelay: number;
            /**
             * The minimum delay (in milliseconds) used by the jitter buffer
             */
            minDelay: number;
          };
          /**
           * This object tracks the the end to end delay(the delay between capture time of sender side and render time of receiver side)
           */
          endToEndDelay?: {
            /**
             * The average delay (in milliseconds) from end to end
             */
            meanDelay: number;
            /**
             * The maximum delay (in milliseconds) from end to end
             */
            maxDelay: number;
            /**
             * The minimum delay (in milliseconds) from end to end
             */
            minDelay: number;
          };
          /**
           * Aggregated end to end delay representing the mean, max, min delay group by csi
           */
          endToEndDelayByCsi?: {
            csi?: number;
            delay?: unknown;
          }[];
        };
        gamestateObjects?: {
          objectId: number;
          numberOfUpdates: number;
          tag: unknown;
          isActive: boolean;
        }[];
      }[];
    }[];
  }[];
}
