import {debounce} from 'lodash-decorators';
import {nonenumerable} from 'core-decorators';
import {make as makeTemplateContainer, oneFlight, tap, whileInFlight} from '@ciscospark/common';
import {evented} from '@ciscospark/common';
import Events from 'ampersand-events';
import {defaults} from 'lodash';
import {parse} from 'sdp-transform';
import {
  ensureH264,
  limitBandwith,
  getMediaDirectionFromTracks,
  kindToPropertyFragment
} from './webrtc-helpers';

import grammar from 'sdp-transform/lib/grammar';

// Add support for our custom "content" attribute. Note: this seems to make
// parse() work correctly, but I don't think I could get write() to work.
if (!grammar.a.find((g) => g.name === `content`)) {
  grammar.a.unshift({
    push: `content`,
    name: `content`,
    reg: /^content:slides/,
    format: `content:slides`
  });
}

const DirectionContainer = makeTemplateContainer(WeakMap, Map);
const targetMediaDirection = new DirectionContainer();

const capitalize = {
  audio: `Audio`,
  video: `Video`
};

/**
 * Wrapper around targetMediaDirection.get which return `inactive` instead of
 * undefined
 * @param {WebRTCMediaEngine} target
 * @param {string} kind
 * @private
 * @returns {string}
 */
function getTargetMediaDirection(target, kind) {
  return targetMediaDirection.get(target, kind) || `inactive`;
}

/**
 * Interface for doing webrtc things
 * @protected
 */
export default class WebRTCMediaEngine {
  /**
   * Wrapper around navigator.mediaDevices.getUserMedia
   *
   * @param {MediaStreamContraints} constraints
   * @returns {Promise<MediaStream>}
   */
  static getUserMedia(constraints) {
    const finalConstraints = defaults({}, constraints, {fake: process.env.NODE_ENV === `test`});
    return navigator.mediaDevices.getUserMedia(finalConstraints);
  }

  logger = console

  @evented
  /**
   * Represents the local party's outgoing stream. Instantiated when the class
   * is instantiated.
   * @type {MediaStream}
   */
  localMediaStream

  @evented
  /**
   * Represent the remote party's incoming media. Instantiated when the class is
   * instantiated.
   * @type {MediaStream}
   */
  remoteMediaStream

  @evented
  /**
   * Reserved for future use
   * @type {MediaStream}
   */
  localScreenShare

  /**
   * Peer Connection
   * @type {RTCPeerConnection}
   */
  pc = new RTCPeerConnection({
    iceServers: [],
    bundlePolicy: `max-compat`
  });

  @evented
  /**
   * The most-recently produced offer
   * @private
   */
  offerSdp = ``;

  @evented
  /**
   * The most-recently accepted answer
   * @private
   */
  answerSdp = ``;

  @evented
  sendingAudio = false;

  @evented
  sendingVideo = false;

  @evented
  receivingAudio = false;

  @evented
  receivingVideo = false;

  @evented
  ended = false;

  bandwidthLimit = {
    audioBandwidthLimit: 60000,
    videoBandwidthLimit: 1000000
  };

  /**
   * Returns the current audio direction
   * @returns {string}
   */
  get audioDirection() {
    return getMediaDirectionFromTracks(`audio`, this.pc);
  }

  /**
   * Returns the current video direction
   * @returns {string}
   */
  get videoDirection() {
    return getMediaDirectionFromTracks(`video`, this.pc);
  }

  /**
   * Returns the current screen direction
   * @returns {string}
   */
  get screenDirection() {
    if (!this.localScreenShare) {
      return `inactive`;
    }
    return this.localScreenShare.getTracks().length === 0 ? `inactive` : `sendonly`;
  }

  /**
   * Constructor
   * @param {Object} attrs
   * @param {Object} options
   * @param {Logger} options.logger (optional): defaults to console
   * @returns {WebRTCMediaEngine}
   */
  constructor(attrs = {}, options = {}) {
    if (options.parent) {
      // This is a bit of weirdness to maintain amp-state compatibility
      process.nextTick(() => {
        if (options.parent.logger) {
          this.logger = options.parent.logger;
        }
      });
    }
    else if (attrs.logger) {
      this.logger = attrs.logger;
    }

    this.pc.onnegotiationneeded = () => {
      if (this.answerSdp) {
        this.logger.info(`peer connection emitted negotiationneeded`);
        this.triggerNegotiationNeeded();
      }
    };

    // Note: adapter.js doesn't seem to fully shim the track event.
    // addEventListener doesn't appear to work for it in chrome
    this.pc.ontrack = (event) => {
      this.trigger(`track`);
      const stream = this.remoteMediaStream || new MediaStream();
      event.streams[0]
        .getTracks()
        .forEach((track) => {
          stream.addTrack(track);
          track.onended = () => {
            stream.removeTrack(track);
            track.onended = undefined;
            try {
              this[`receiving${capitalize[track.kind]}`] = getMediaDirectionFromTracks(track.kind, this.pc).includes(`recv`);
            }
            catch (err) {
              this[`receiving${capitalize[track.kind]}`] = false;
            }
          };

          this[`receiving${capitalize[track.kind]}`] = getMediaDirectionFromTracks(track.kind, this.pc).includes(`recv`);
        });
      this.remoteMediaStream = stream;
    };
  }

  /* eslint-disable complexity */
  /**
   * Determines if ice gathering is necessary and sends it up when appropriate
   * @private
   * @returns {Promise|undefined}
   */
  _prepareIceGatherer() {
    let needsIce = false;
    if (this.pc.iceGatheringState === `new`) {
      this.logger.info(`ice gathering is in state "new", definitely need to block for ice gathering`);
      needsIce = true;
    }
    else {
      const sdp = parse(this.pc.localDescription.sdp);
      [
        `audio`,
        `video`,
        `screen`
      ].forEach((kind) => {
        const directionKey = `${kind}Direction`;
        if (this[directionKey] !== `inactive` || getTargetMediaDirection(this, kind) !== this[directionKey] && getTargetMediaDirection(this, kind) !== `inactive`) {
          const media = sdp.media.find((m) => m.type === kind);
          if (media) {
            this.logger.info(`${kind} candidates already gathered`);
          }
          else {
            this.logger.info(`transitioning ${kind} from inactive, ice needed`);
            needsIce = true;
          }
        }
      });
    }

    let icePromise;
    if (needsIce) {
      icePromise = new Promise((resolve) => {
        this.logger.info(`configuring ice gathering`);
        this.pc.onicecandidate = (event) => {
          if (!event.candidate) {
            this.logger.info(`ice gathering complete`);
            this.pc.onicecandidate = undefined;
            resolve();
            return;
          }

          this.logger.info(`got ice candidate`);
        };

      });
    }

    return icePromise;
  }
  /* eslint-enable complexity */

  /**
   * Creates an offer SDP
   * @returns {Promise<string>}
   */
  createOffer() {
    this.logger.info(`beginning negotiation`);

    const td = getTargetMediaDirection(this, `video`);
    const wantsVideo = td.includes(`send`) || td.includes(`recv`);

    const icePromise = this._prepareIceGatherer();

    return new Promise((resolve) => {
      if (this.gumming) {
        this.logger.info(`gum in flight, waiting until it completes`);
        // Since gum is protected by @oneflight, returning it here will block
        // until it completes but, more importantly, propagate a thrown
        // exception up the stack
        resolve(this._getUserMedia());
        return;
      }

      resolve();
    })
      .then(() => {
        this.pc.addStream(new MediaStream());
      })
      .then(tap(() => this.logger.info(`creating offer`, this.offerOptions)))
      .then(() => {
        // This is a (hopefully temporary) hack to deal with the fact that one
        // out of two browsers removes the remote stream when offerToReceive* is
        // false. We've already made the choice to disable the stream, but we
        // want to make sure we're still willing to receive an answer for it.
        this.offerOptions.offerToReceiveAudio = this.offerOptions.offerToReceiveAudio || !!this.pc.getReceivers().find((r) => r.track.kind === `audio`);
        this.offerOptions.offerToReceiveVideo = this.offerOptions.offerToReceiveVideo || !!this.pc.getReceivers().find((r) => r.track.kind === `video`);
        return this.pc.createOffer(this.offerOptions);
      })
      .then(tap((offer) => {
        offer.sdp = limitBandwith(this.bandwidthLimit, offer.sdp);
      }))
      .then(tap(() => this.logger.info(`setting local description`)))
      .then((offer) => this.pc.setLocalDescription(offer))
      .then(tap(() => icePromise && this.logger.info(`blocking for ice gathering`)))
      .then(() => icePromise)
      .then(tap(() => this.logger.info(`limiting bandwith`)))
      .then(() => limitBandwith(this.bandwidthLimit, this.pc.localDescription.sdp))
      .then(tap(() => wantsVideo && this.logger.info(`confirm h264 in offer`)))
      .then(ensureH264(wantsVideo))
      .then((sdp) => {
        if (this.localScreenShare) {
          const streamId = this.localScreenShare.id;
          const track = this.localScreenShare.getVideoTracks()[0];
          if (track) {
            const trackId = track.id;
            const msid = `${streamId} ${trackId}`;
            const sections = sdp.split(msid);
            if (sections.length < 2) {
              throw new Error(`SDP does not appear to carrey correct screenshare information`);
            }
            else {
              sections[1] = `\r\na=content:slides${sections[1]}`;
              sdp = sections.join(msid);
            }
          }
          else {
            sdp += `a=content:slides\r\n`;
          }
        }
        return sdp;
      })
      .then(tap((sdp) => {
        this.offerSdp = sdp;
      }));
  }

  /**
   * Receives an answer SDP
   * @param {string} sdp
   * @returns {Promise}
   */
  acceptAnswer(sdp) {
    this.logger.info(`accepting answer`);

    // Allow larger frames (this makes screenshare look *way* better, but no
    // idea what impact it's having on the camera stream - we may want to limit
    // it to just screen share at some future point)
    const defaultCodecParams = /max-mbps=27600;max-fs=920/g;
    const newCodecParams = `max-mbps=27600;max-fs=8160`;
    sdp = sdp.replace(defaultCodecParams, newCodecParams);

    // If the screenshare goes inactive, make sure the sdp includes a direction
    // config
    sdp = sdp.replace(/m=video 0(.*?\r\n)/, `m=video 0$1a=inactive\r\n`);

    return this.pc.setRemoteDescription(new RTCSessionDescription({
      sdp,
      type: `answer`
    }))
      .then(() => {
        this.logger.info(`answer accepted`);
        this.answerSdp = sdp;
        this.sendingAudio = getMediaDirectionFromTracks(`audio`, this.pc).includes(`send`);
        this.sendingVideo = getMediaDirectionFromTracks(`video`, this.pc).includes(`send`);
        this.trigger(`answeraccepted`);
      });
  }

  @nonenumerable
  /**
   * {@link MediaStreamConstraints} that'll be used for the next call to
   * {@link WebRTCMediaEngine.getUserMedia()}
   * @private
   * @type {MediaStreamConstraints}
   */
  constraints = {};

  @nonenumerable
  /**
   * {@link RTCOfferOptions} that'll be used for the next call to
   * {@link RTCPeerConnection.createOffer}
   * @private
   * @type {RTCOfferOptions}
   */
  offerOptions = {};

  @nonenumerable
  @evented
  /**
   * Indicates whether or not a call to {@link MediaDevices#getUserMedia()} is
   * in flight
   * @private
   * @type {boolean}
   */
  gumming = false

  /**
   * Change media direction without consumer provided tracks or complex
   * constraints
   * @param {string} kind
   * @param {string} direction
   * @private
   * @returns {undefined}
   */
  _setNewMediaDirection(kind, direction) {
    this.logger.info(`setting ${kind} direction to ${direction}`);
    const constraint = direction.includes(`send`);
    this.constraints[kind] = constraint;

    if (constraint) {
      if (!this[`${kind}Direction`].includes(`send`)) {
        this._setNewMediaConstraint(kind, constraint);
      }
    }
    else {
      this.logger.info(`removing any no-longer-needed ${kind} tracks`);
      if (!this.localMediaStream) {
        return;
      }
      this.localMediaStream
        .getTracks()
        .filter((t) => t.kind === kind)
        .forEach((t) => {
          this.logger.info(`removing ${kind} track ${t.id} from localMediaStream`);
          this.localMediaStream.removeTrack(t);
          this.logger.info(`removing ${kind} track ${t.id} from peer connection`);
          // Note: Doesn't like removing senders whose tracks are not live, so
          // t.stop() has to come after removeTrack()
          try {
            this.pc.removeTrack(this.pc.getSenders().find((s) => s.track === t));
          }
          catch (err) {
            if (t.readyState === `ended`) {
              this.logger.warn(`Suppressing error caused by trying to remove an ended track from a peer connection`);
            }
            else {
              this.logger.warn(`suppressing removeTrack error. We don't know why firefox does this, but we're still going to make sure the track is stopped`);
            }
            this.logger.warn(err);
          }
          this.logger.info(`setting receiving${capitalize[kind]} to false`);
          this[`sending${capitalize[kind]}`] = false;
          this.logger.info(`stopping ${kind} track ${t.id}`);
          t.stop();
        });
    }
  }

  /**
   * Sets or replaces current track for $kind
   * @param {string} kind
   * @param {MediaStreamTrack} track
   * @returns {undefined}
   */
  _setNewMediaTrack(kind, track) {
    this.logger.info(`setting new ${kind} track`);
    this.constraints[kind] = false;
    this.addOrReplaceTrack(track);
  }

  /**
   * Causes track for ${kind} to be set or replaced according to $constraint
   * @param {string} kind
   * @param {Object|boolean} constraint
   * @returns {undefined}
   */
  _setNewMediaConstraint(kind, constraint) {
    this.logger.info(`setting ${kind} with new constraint`);
    this.constraints[kind] = constraint;
    this._getUserMedia();
  }

  /**
   * Starts or stops an outbound screenshare
   *
   * @param {string} direction currently only inactive or sendonly
   * @param {Object|MediaStreamTrack} trackOrConstraint
   * @returns {Promise}
   */
  _setScreenShare(direction, trackOrConstraint) {
    this.logger.info(`calling _setScreenShare`);
    targetMediaDirection.set(this, `screen`, direction);
    if (direction.includes(`send`)) {
      const constraints = {
        video: defaults({}, trackOrConstraint, {
          mediaSource: `application`,
          width: {
            min: `160`,
            max: `1920`
          },
          height: {
            min: `90`,
            max: `1080`
          },
          frameRate: {
            min: `1`,
            max: `30`
          }
        })
      };

      this.logger.info(`sharing ${constraints.video.mediaSource}`);
      return WebRTCMediaEngine.getUserMedia(constraints)
        .then((stream) => {
          this.logger.info(`got stream with ${constraints.video.mediaSource} track`);
          if (this.localScreenShare) {
            this.logger.info(`removing existing screenshare tracks from peer connection and localScreenShare stream`);
            this.pc.getSenders()
              .filter((s) => this.localMediaStream.getTracks().includes(s.track))
              .forEach((s) => {
                this.pc.removeTrack(s);
                this.localMediaStream.removeTrack(s.track);
              });

            this.logger.info(`adding new screen track to localScreenShare stream`);
            stream.getTracks().forEach((t) => this.localScreenShare.addTrack(t));
          }
          else {
            this.logger.info(`adding localScreenShare for the first time`);
            this.localScreenShare = stream;
          }

          this.logger.info(`adding new screenshare track to peer connection`);
          stream.getVideoTracks().forEach((t) => this.pc.addTrack(t, stream));
        })
        .catch((err) => {
          this.logger.error(`screenshare failed`);
          this.logger.error(err);
          this.trigger(err);
          return Promise.reject(err);
        });
    }

    this.logger.info(`removing existing screenshare tracks from peer connection and localScreenShare stream`);
    this.pc.getSenders()
      .filter((s) => this.localScreenShare.getTracks().includes(s.track))
      .forEach((s) => {
        this.logger.info(`removing screenshare sender`);
        this.pc.removeTrack(s);
        this.logger.info(`removing track ${s.track.id} from local screenshare stream`);
        this.localScreenShare.removeTrack(s.track);
        this.logger.info(`stopping screenshare track`);
        s.track.stop();
      });

    return Promise.resolve();
  }

  // I don't see any further ways to reduce complexity without hurting
  // readability
  /* eslint-disable complexity */
  /**
   * Sets a media direction for a given media type. Almost certainly triggers
   * renegotiation. This is the method to use if you want to replace a track.
   * @param {string} kind audio|video
   * @param {string} direction sendonly|recvonly|sendrecv|inactive
   * @param {MediaStreamTrack|Object} trackOrConstraint
   * @returns {Promise}
   */
  setMedia(kind, direction, trackOrConstraint) {
    this.logger.info(`setMedia`);
    if (kind === `screen`) {
      this.logger.info(`setMedia: setting new screen direction`);
      this._setScreenShare(direction, trackOrConstraint);
      return;
    }
    if (trackOrConstraint) {
      if (!direction.includes(`send`)) {
        throw new Error(`Cannot set new ${kind} track or constraint if direction does not include send`);
      }

      if (trackOrConstraint instanceof MediaStreamTrack) {
        if (trackOrConstraint.kind !== kind) {
          throw new Error(`track is not a valid ${kind} media stream track`);
        }

        this._setNewMediaTrack(kind, trackOrConstraint);
      }
      else {
        this._setNewMediaConstraint(kind, trackOrConstraint);
      }
    }
    else {
      if (direction === getTargetMediaDirection(this, kind)) {
        this.logger.info(`${kind} already transitioning to ${direction}, not making changes`);
        return;
      }

      if (direction === this[`${kind}Direction`]) {
        this.logger.info(`${kind} already set to ${direction}, not making changes`);
        return;
      }
      this._setNewMediaDirection(kind, direction);
    }

    const shouldRecv = direction.includes(`recv`);

    targetMediaDirection.set(this, kind, direction);

    this.offerOptions[`offerToReceive${kindToPropertyFragment(kind)}`] = shouldRecv;

    if (shouldRecv) {
      if (this.remoteMediaStream && this.remoteMediaStream.getTracks().find((t) => t.kind === kind)) {
        this.unpauseReceivingMedia(kind);
      }
      else if (this.answerSdp) {
        this.triggerNegotiationNeeded();
      }
    }
    else if (this.remoteMediaStream && this.remoteMediaStream.getTracks().find((t) => t.kind === kind)) {
      this.pauseReceivingMedia(kind);
    }
  }
  /* eslint-enable complexity */

  @whileInFlight(`gumming`)
  @oneFlight
  /**
   * Wrapper around {@link MediaDevices#getUserMedia()} that delays the call one
   * tick to reduce the number of permissions dialogs presented to the user.
   * @returns {Promise<MediaStream>}
   */
  _getUserMedia() {
    this.logger.info(`enqueing request to get user media`);
    return new Promise((resolve) => process.nextTick(resolve))
      .then(() => {
        if (this.constraints.audio === true && this.pc.getSenders().find((s) => s.track.kind === `audio`)) {
          this.logger.info(`already have a local audio track, removing constraint for a second one`);
          Reflect.deleteProperty(this.constraints, `audio`);
        }

        if (this.constraints.video === true && this.pc.getSenders().find((s) => s.track.kind === `video`)) {
          this.logger.info(`already have a local video track, removing constraint for a second one`);
          Reflect.deleteProperty(this.constraints, `video`);
        }

        return WebRTCMediaEngine.getUserMedia(this.constraints);
      })
      .then((stream) => {
        this.logger.info(`got local media stream with ${stream.getAudioTracks().length} audio tracks and ${stream.getVideoTracks().length} video tracks`);
        stream.getTracks().forEach((t) => this.addOrReplaceTrack(t));
        this.constraints = {};
      })
      .catch((err) => {
        this.trigger(`error`, err);
        return Promise.reject(err);
      });
  }

  /**
   * adds or replaces a local @{link MediaStreamTrack}
   * @private
   * @param {MediaStreamTrack} track
   * @returns {undefined}
   */
  addOrReplaceTrack(track) {
    if (!this.localMediaStream) {
      this.localMediaStream = new MediaStream();
    }
    this.logger.info(`preparing to add ${track.kind} to local media stream`);
    const existing = this.pc.getSenders().find((s) => s.track.kind === track.kind && s.track !== track);
    if (existing) {
      this.logger.info(`removing previous ${track.kind} from local media stream`);
      this.pc.removeTrack(existing);
      this.localMediaStream.removeTrack(existing.track);
      // it may not be appropriate to stop the track if it was supplied by the
      // engine consumer, but I'm inclined not to deal with that unless it
      // becomes a real issue.
      track.stop();
    }

    this.logger.info(`adding ${track.kind} to local media stream`);
    this.localMediaStream.addTrack(track);
    this.logger.info(`adding ${track.kind} to peer connection`);
    this.pc.addTrack(track, this.localMediaStream);

    this.logger.info(`setting sending${capitalize[track.kind]} to true`);
    this[`sending${capitalize[track.kind]}`] = true;
  }

  /**
   * Stops sending useful bits on the identified track, but does not end it (the
   * camera/mic will stay on but the remote party(s) will not see/hear anything).
   * Avoids renegotiation. Throws if `kind` does not identify a track.
   * @param {string} kind
   * @returns {Promise}
   */
  pauseSendingMedia(kind) {
    if (!kind) {
      throw new Error(`kind is required`);
    }
    const senders = this.pc
      .getSenders()
      .filter((s) => s.track.kind === kind);

    if (senders.length === 0) {
      throw new Error(`No ${kind} media senders to pause`);
    }

    senders.forEach((s) => {
      this.logger.info(`pausing ${kind} sender`);
      s.track.enabled = false;
    });

    this.logger.info(`setting sending${capitalize[kind]} to false`);
    this[`sending${capitalize[kind]}`] = false;
  }

  /**
   * Resumes sending bits on the identified track. Throws if `kind` does not
   * identify a track.
   * @param {string} kind
   * @returns {Promise}
   */
  unpauseSendingMedia(kind) {
    if (!kind) {
      throw new Error(`kind is required`);
    }
    const senders = this.pc
      .getSenders()
      .filter((s) => s.track.kind === kind);

    if (senders.length === 0) {
      throw new Error(`No ${kind} media senders to unpause`);
    }

    senders.forEach((s) => {
      this.logger.info(`unpausing ${kind} sender`);
      s.track.enabled = true;
    });

    this.logger.info(`setting sending${capitalize[kind]} to true`);
    this[`sending${capitalize[kind]}`] = true;
  }

  /**
   * Convenience function. Sets a remote track.enabled=false. Does not
   * renegotiate.Throws if `kind` does not identify a track.
   * @param {string} kind
   * @returns {Promise}
   */
  pauseReceivingMedia(kind) {
    if (!kind) {
      throw new Error(`kind is required`);
    }
    if (!this.remoteMediaStream) {
      throw new Error(`No remote media stream available`);
    }
    const tracks = this.remoteMediaStream
      .getTracks()
      .filter((t) => t.kind === kind);

    if (tracks.length === 0) {
      throw new Error(`No remote ${kind} media tracks to pause`);
    }


    tracks.forEach((t) => {
      this.logger.info(`pausing remote ${kind} track`);
      t.enabled = false;
    });

    this.logger.info(`setting receiving${capitalize[kind]} to false`);
    this[`receiving${capitalize[kind]}`] = false;
  }

  /**
   * Convenience function. Sets a remote track.enabled=true. Does not
   * renegotiate.Throws if `kind` does not identify a track.
   * @param {string} kind
   * @returns {Promise}
   */
  unpauseReceivingMedia(kind) {
    if (!kind) {
      throw new Error(`kind is required`);
    }
    if (!this.remoteMediaStream) {
      throw new Error(`No remote media stream available`);
    }
    const tracks = this.remoteMediaStream
      .getTracks()
      .filter((t) => t.kind === kind);

    if (tracks.length === 0) {
      throw new Error(`No remote ${kind} media tracks to pause`);
    }

    tracks.forEach((t) => {
      this.logger.info(`unpausing remote ${kind} track`);
      t.enabled = true;
    });

    this.logger.info(`setting receiving${capitalize[kind]} to true from ${this[`receiving${capitalize[kind]}`]}`);
    this[`receiving${capitalize[kind]}`] = true;
  }

  /**
   * Stops all tracks and streams, closes the peer connection, and removes all
   * listeners
   * @returns {undefined}
   */
  stop() {
    if (this.pc.signalingState !== `closed`) {
      this.pc.getSenders().forEach((s) => s.track.stop());
      this.pc.close();
    }

    this.pc.onnegotiationneeded = undefined;
    this.pc.ontrack = undefined;
    this.pc.onicecandidate = undefined;
    this.ended = true;
    this.off();
  }

  @debounce(500)
  /**
   * Debounced helper for triggering `negotiationneeded`.
   * @private
   * @returns {undefined}
   */
  // It's not missing, but the decorator is throwing off eslint
  // eslint-disable-next-line require-jsdoc
  triggerNegotiationNeeded() {
    this.trigger(`negotiationneeded`);
  }
}

Object.assign(WebRTCMediaEngine.prototype, Events);
