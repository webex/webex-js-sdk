/* global step: false */

import browser from 'bowser';
import 'mocha-steps';
import {assert} from '@ciscospark/test-helper-chai';
import {browserOnly, expectEvent, firefoxOnly, handleErrorEvent} from '@ciscospark/test-helper-mocha';
import sinon from '@ciscospark/test-helper-sinon';
import WebRTCMediaEngine, {webrtcHelpers} from '@ciscospark/media-engine-webrtc';

import {mockAnswer, mockRenegotiate} from '../lib/offer-answer';

const {
  getMediaDirectionFromSDP,
  getMediaFromSDP,
  reverseMediaDirection
} = webrtcHelpers;

function getExpectedMediaDirection(next, previous) {
  if (previous.includes('recv')) {
    if (next === 'inactive') {
      return 'recvonly';
    }
    if (next === 'sendonly') {
      return 'sendrecv';
    }
  }

  return next;
}

const backoffPattern = [0, 100, 200, 400, 800];

function retry(fn) {
  return backoffPattern.reduce((promise, delay) => promise.catch(() => new Promise((resolve, reject) => {
    setTimeout(() => {
      try {
        resolve(fn());
      }
      catch (err) {
        reject(err);
      }
    }, delay);
  })), Promise.reject());
}

browserOnly(describe)('media-engine-webrtc', function () {
  this.timeout(60000);
  describe('WebRTCMediaEngine', () => {
    describe('#logger', () => {
      it('defaults to console', () => {
        const engine = new WebRTCMediaEngine();
        assert.equal(engine.logger, console);
      });

      it('proxies to the spark logger', () => {
        const engine = new WebRTCMediaEngine(null, {
          parent: {
            logger: {}
          }
        });

        assert.equal(engine.logger, console);
        return Promise.resolve()
          .then(() => new Promise((resolve) => process.nextTick(resolve)))
          .then(() => {
            assert.isDefined(engine.logger);
            assert.notEqual(engine.logger, console);
          });
      });
    });

    describe('renegotiation', () => {
      const audioStartStates = [
        'inactive',
        'recvonly',
        'sendonly',
        'sendrecv'
      ];

      const audioEndStates = [
        'inactive',
        'recvonly',
        'sendonly',
        'sendrecv'
      ];

      const videoStartStates = [
        'inactive',
        'recvonly',
        'sendonly',
        'sendrecv'
      ];

      const videoEndStates = [
        'inactive',
        'recvonly',
        'sendonly',
        'sendrecv'
      ];

      audioStartStates.forEach((audioStart) => {
        audioEndStates.forEach((audioEnd) => {
          videoStartStates.forEach((videoStart) => {
            // all the complexity comes from building the `describe()` block
            // message
            // eslint-disable-next-line complexity
            videoEndStates.forEach((videoEnd) => {
              if (audioStart === 'inactive' && videoStart === 'inactive') {
                // not a valid initial state
                return;
              }

              if (audioEnd === 'inactive' && videoEnd === 'inactive') {
                return;
              }

              if (audioStart === audioEnd && videoStart === videoEnd) {
                // no changes, therefore nothing to test
                return;
              }

              // Scenarios that involve adding a remote stream after the the
              // call has started seem flaky in Chrome. They pass on occasion,
              // but more oftent than not, the `track` event doesn't fire. I
              // can't tell if this is a Chrome bug or an adapter.js bug and so
              // far, I've not been able to reproduce in isolation, so I don't
              // have a means of providing a reproduction case.
              // TODO keep an eye on this as Chrome and adapter.js update
              const flakyInChrome = !audioStart.includes('recv') && audioEnd.includes('recv') || !videoStart.includes('recv') && videoEnd.includes('recv');

              // Firefox does doesn't include ice credentials when renegotiating
              // a media stream into an inactive state, but the mock peer
              // expects said credentials. We're not sure if this bug will
              // impact the real world, but we plan to minimize renegotation
              // that transitions to inactive and don't expect major issues.
              // More details in `renegotiation-support.md`
              const brokenInFirefox = audioStart === 'inactive' && audioEnd === 'sendonly'
                || audioStart === 'sendonly'
                || audioStart === 'sendrecv' && audioEnd === 'inactive'
                || audioStart === 'sendrecv' && audioEnd === 'recvonly'
                || videoStart === 'inactive' && videoEnd === 'sendonly'
                || videoStart === 'sendonly'
                || videoStart === 'sendrecv' && videoEnd === 'inactive'
                || videoStart === 'sendrecv' && videoEnd === 'recvonly'
                || audioStart !== 'inactive' && audioEnd === 'inactive' && videoStart === 'inactive' && videoEnd !== 'inactive'
                || audioStart === 'inactive' && audioEnd !== 'inactive' && videoStart !== 'inactive' && videoEnd === 'inactive';


              const brokenInChrome = audioStart !== 'inactive' && audioEnd === 'inactive' || audioStart === 'inactive' && audioEnd !== 'inactive';

              const shouldSkip = (browser.chrome && (flakyInChrome || brokenInChrome)) || (browser.firefox && brokenInFirefox);

              let expectNewRemoteTrackOnTransition = false;
              expectNewRemoteTrackOnTransition = expectNewRemoteTrackOnTransition || audioStart.includes('recv') !== audioEnd.includes('recv') && (audioEnd.includes('recv'));
              expectNewRemoteTrackOnTransition = expectNewRemoteTrackOnTransition || videoStart.includes('recv') !== videoEnd.includes('recv') && (videoEnd.includes('recv'));
              let expectToRenegotiateOnTransition = expectNewRemoteTrackOnTransition;
              expectToRenegotiateOnTransition = expectToRenegotiateOnTransition || audioStart.includes('send') !== audioEnd.includes('send') && (audioStart.includes('send') || audioEnd.includes('send'));
              expectToRenegotiateOnTransition = expectToRenegotiateOnTransition || videoStart.includes('send') !== videoEnd.includes('send') && (videoStart.includes('send') || videoEnd.includes('send'));

              let sendingAudioChange = false;
              sendingAudioChange = audioStart.includes('send') !== audioEnd.includes('send');

              let sendingVideoChange = false;
              sendingVideoChange = videoStart.includes('send') !== videoEnd.includes('send');

              let receivingAudioChange = false;
              receivingAudioChange = audioStart.includes('recv') !== audioEnd.includes('recv');

              let receivingVideoChange = false;
              receivingVideoChange = videoStart.includes('recv') !== videoEnd.includes('recv');

              const expectNewRemoteTrackOnReturn = false;
              let expectToRenegotiateOnReturn = expectNewRemoteTrackOnReturn;
              expectToRenegotiateOnReturn = expectToRenegotiateOnReturn || audioStart.includes('send') !== audioEnd.includes('send') && (audioStart.includes('send') || audioEnd.includes('send'));
              expectToRenegotiateOnReturn = expectToRenegotiateOnReturn || videoStart.includes('send') !== videoEnd.includes('send') && (videoStart.includes('send') || videoEnd.includes('send'));

              const message = `when ${[
                audioStart === audioEnd ? `audio is '${audioStart}'` : `audio changes from '${audioStart}' to '${audioEnd}'`,
                videoStart === videoEnd ? `video is '${videoStart}'` : `video changes from '${videoStart}' to '${videoEnd}'`
              ]
                .filter((m) => m)
                .join(' and ')}`;

              describe(message, () => {
                // Note: This describe block is stateful; `step()` statements must
                // execute in order.
                let engine;
                before(() => {
                  engine = new WebRTCMediaEngine();
                });

                after(() => {
                  engine.stop();
                });


                (shouldSkip ? it.skip : step)(`initiates a session with audio=${audioStart} and video=${videoStart}`, () => {
                  engine.setMedia('audio', audioStart);
                  engine.setMedia('video', videoStart);


                  return engine.createOffer()
                    .then((offer) => {
                      assertLocalMedia(engine, audioStart, videoStart);

                      assert.equal(getMediaDirectionFromSDP('audio', offer), audioStart);
                      assert.equal(getMediaDirectionFromSDP('video', offer), videoStart);
                      return offer;
                    })
                    .then(mockAnswer)
                    .then((answer) => {
                      assertLocalMedia(engine, audioStart, videoStart);

                      assert.equal(getMediaDirectionFromSDP('audio', answer), reverseMediaDirection(audioStart));
                      assert.equal(getMediaDirectionFromSDP('video', answer), reverseMediaDirection(videoStart));
                      return answer;
                    })
                    .then((answer) => Promise.all([
                      (audioStart.includes('recv') || videoStart.includes('recv')) && expectEvent(20000, 'track', engine),
                      engine.acceptAnswer(answer)
                    ]))
                    .then(() => {
                      assertLocalMedia(engine, audioStart, videoStart);
                      assertRemoteMedia(engine, audioStart, videoStart);

                      assert.equal(engine.audioDirection, audioStart);
                      assert.equal(engine.videoDirection, videoStart);
                    });
                });

                (shouldSkip ? it.skip : step)(`transitions to audio=${audioEnd} and video=${videoEnd}`, () => {
                  const sendingAudioSpy = sinon.spy();
                  const sendingVideoSpy = sinon.spy();
                  const receivingAudioSpy = sinon.spy();
                  const receivingVideoSpy = sinon.spy();

                  engine.once('change:sendingAudio', sendingAudioSpy);
                  engine.once('change:sendingVideo', sendingVideoSpy);
                  engine.once('change:receivingAudio', receivingAudioSpy);
                  engine.once('change:receivingVideo', receivingVideoSpy);

                  const negotiationneededSpy = sinon.spy();
                  const trackSpy = sinon.spy();

                  engine.once('negotiationneeded', negotiationneededSpy);
                  engine.once('track', trackSpy);

                  engine.setMedia('audio', audioEnd);
                  engine.setMedia('video', videoEnd);

                  return Promise.all([
                    expectToRenegotiateOnTransition && expectEvent(20000, 'negotiationneeded', engine)
                      .then(() => retry(() => assertLocalMedia(engine, audioEnd, videoEnd)))
                      .then(() => engine.createOffer())
                      .then((offer) => {
                        assertOffer('audio', audioEnd, audioStart, offer);
                        assertOffer('video', videoEnd, videoStart, offer);
                        return offer;
                      })
                      .then(mockRenegotiate)
                      .then((answer) => {
                        assertAnswer('audio', audioEnd, audioStart, answer);
                        assertAnswer('video', videoEnd, videoStart, answer);

                        return answer;
                      })
                      .then((answer) => engine.acceptAnswer(answer)),
                    expectNewRemoteTrackOnTransition && expectEvent(20000, 'track', engine)
                  ])
                    .then(() => {
                      assertLocalMedia(engine, audioEnd, videoEnd);
                      assertRemoteMedia(engine, audioEnd, videoEnd);
                      assert.equal(engine.audioDirection, audioEnd);
                      assert.equal(engine.videoDirection, videoEnd);
                    })
                    .then(() => {
                      assertSpyCalledOrNot(expectToRenegotiateOnTransition, negotiationneededSpy);
                      assertSpyCalledOrNot(expectNewRemoteTrackOnTransition, trackSpy);

                      assertSpyCalledOrNot(sendingAudioChange, sendingAudioSpy);
                      assertSpyCalledOrNot(sendingVideoChange, sendingVideoSpy);
                      assertSpyCalledOrNot(receivingAudioChange, receivingAudioSpy);
                      assertSpyCalledOrNot(receivingVideoChange, receivingVideoSpy);
                    });
                });

                (shouldSkip ? it.skip : step)(`returns to audio=${audioStart} and video=${videoStart}`, () => {
                  const sendingAudioSpy = sinon.spy();
                  const sendingVideoSpy = sinon.spy();
                  const receivingAudioSpy = sinon.spy();
                  const receivingVideoSpy = sinon.spy();

                  engine.once('change:sendingAudio', sendingAudioSpy);
                  engine.once('change:sendingVideo', sendingVideoSpy);
                  engine.once('change:receivingAudio', receivingAudioSpy);
                  engine.once('change:receivingVideo', receivingVideoSpy);

                  const negotiationneededSpy = sinon.spy();
                  const trackSpy = sinon.spy();

                  engine.once('negotiationneeded', negotiationneededSpy);
                  engine.once('track', trackSpy);

                  engine.setMedia('audio', audioStart);
                  engine.setMedia('video', videoStart);

                  return Promise.resolve(expectToRenegotiateOnReturn && expectEvent(20000, 'negotiationneeded', engine)
                    .then(() => engine.createOffer())
                    .then((offer) => {
                      // FF59 has two offer sections after changing
                      assertOffer('audio', audioStart, audioEnd, offer);
                      assertOffer('video', videoStart, videoEnd, offer);

                      return offer;
                    })
                    .then(mockRenegotiate)
                    .then((answer) => {
                      assertAnswer('audio', audioStart, audioEnd, answer);
                      assertAnswer('video', videoStart, videoEnd, answer);

                      return answer;
                    })
                    .then((answer) => Promise.all([
                      expectNewRemoteTrackOnReturn && expectEvent(20000, 'track', engine),
                      engine.acceptAnswer(answer)
                    ])))
                    .then(() => {
                      assertLocalMedia(engine, audioStart, videoStart);
                      assertRemoteMedia(engine, audioStart, videoStart);

                      assert.equal(engine.audioDirection, audioStart, `expected "audio" to return to "${audioStart}"`);
                      assert.equal(engine.videoDirection, videoStart, `expected "video" to return to "${videoStart}"`);
                    })
                    .then(() => {
                      assertSpyCalledOrNot(expectToRenegotiateOnReturn, negotiationneededSpy);
                      assertSpyCalledOrNot(expectNewRemoteTrackOnReturn, trackSpy);

                      assertSpyCalledOrNot(sendingAudioChange, sendingAudioSpy);
                      assertSpyCalledOrNot(sendingVideoChange, sendingVideoSpy);
                      assertSpyCalledOrNot(receivingAudioChange, receivingAudioSpy);
                      assertSpyCalledOrNot(receivingVideoChange, receivingVideoSpy);
                    });
                });
              });
            });
          });
        });
      });
    });

    [
      'audio',
      'video'
    ]
      .forEach((kind) => {
        describe(`#(un)pauseSendingMedia(${kind})`, () => {
          it(`pauses the outgoing ${kind} stream but does not trigger renegotiation`, () => {
            const engine = new WebRTCMediaEngine();
            engine.setMedia('audio', 'sendrecv');
            engine.setMedia('video', 'sendrecv');
            const spy = sinon.spy();

            return engine.createOffer()
              .then(mockAnswer)
              .then((answer) => Promise.all([
                expectEvent(20000, 'track', engine),
                engine.acceptAnswer(answer)
              ]))
              .then(() => {
                assertLocalMedia(engine, 'sendrecv', 'sendrecv');
                assertRemoteMedia(engine, 'sendrecv', 'sendrecv');

                engine.on('negotiationneeded', spy);
                engine.pauseSendingMedia(kind);
                assert.isFalse(engine.pc.getSenders().find((s) => s.track && s.track.kind === kind).track.enabled);
                assert.isFalse(engine.localMediaStream.getTracks().find((t) => t.kind === kind).enabled);
                // I don't know a better way to assert an event doesn't fire than
                // to wait a while and assert it didn't fire.
                return new Promise((resolve) => setTimeout(resolve, 500));
              })
              .then(() => assert.notCalled(spy))
              .then(() => {
                assertLocalMedia(engine, kind === 'audio' ? 'recvonly' : 'sendrecv', kind === 'video' ? 'recvonly' : 'sendrecv');
                assertRemoteMedia(engine, kind === 'audio' ? 'recvonly' : 'sendrecv', kind === 'video' ? 'recvonly' : 'sendrecv');

                engine.on('negotiationneeded', spy);
                engine.unpauseSendingMedia(kind);
                assert.isTrue(engine.pc.getSenders().find((s) => s.track && s.track.kind === kind).track.enabled);
                assert.isTrue(engine.localMediaStream.getTracks().find((t) => t.kind === kind).enabled);
                // I don't know a better way to assert an event doesn't fire than
                // to wait a while and assert it didn't fire.
                return new Promise((resolve) => setTimeout(resolve, 500));
              })
              .then(() => assert.notCalled(spy));
          });
        });

        describe(`#(un)pauseReceivingMedia(${kind})`, () => {
          it(`pauses the outgoing ${kind} stream but does not trigger renegotiation`, () => {
            const engine = new WebRTCMediaEngine();
            engine.setMedia('audio', 'sendrecv');
            engine.setMedia('video', 'sendrecv');
            const spy = sinon.spy();

            return engine.createOffer()
              .then(mockAnswer)
              .then((answer) => Promise.all([
                expectEvent(20000, 'track', engine),
                engine.acceptAnswer(answer)
              ]))
              .then(() => {
                assertLocalMedia(engine, 'sendrecv', 'sendrecv');
                assertRemoteMedia(engine, 'sendrecv', 'sendrecv');

                engine.on('negotiationneeded', spy);
                engine.pauseReceivingMedia(kind);
                assert.isFalse(engine.pc.getRemoteStreams()[0].getTracks().find((t) => t.kind === kind).enabled);
                assert.isFalse(engine.remoteMediaStream.getTracks().find((t) => t.kind === kind).enabled);
                // I don't know a better way to assert an event doesn't fire than
                // to wait a while and assert it didn't fire.
                return new Promise((resolve) => setTimeout(resolve, 500));
              })
              .then(() => assert.notCalled(spy))
              .then(() => {
                assertLocalMedia(engine, kind === 'audio' ? 'sendonly' : 'sendrecv', kind === 'video' ? 'sendonly' : 'sendrecv');
                assertRemoteMedia(engine, kind === 'audio' ? 'sendonly' : 'sendrecv', kind === 'video' ? 'sendonly' : 'sendrecv');

                engine.on('negotiationneeded', spy);
                engine.unpauseReceivingMedia(kind);
                assert.isTrue(engine.pc.getRemoteStreams()[0].getTracks().find((t) => t.kind === kind).enabled);
                assert.isTrue(engine.remoteMediaStream.getTracks().find((t) => t.kind === kind).enabled);
                // I don't know a better way to assert an event doesn't fire than
                // to wait a while and assert it didn't fire.
                return new Promise((resolve) => setTimeout(resolve, 500));
              })
              .then(() => assert.notCalled(spy));
          });
        });
      });

    describe('custom track', () => {
      let engine;
      beforeEach(() => {
        engine = new WebRTCMediaEngine();
      });

      afterEach(() => {
        engine.stop();
      });


      it('adds a track without internally calling getusermedia', () => {
        let track;
        const spy = sinon.spy(engine, '_getUserMedia');

        return WebRTCMediaEngine.getUserMedia({
          audio: true,
          video: false
        })
          .then((stream) => {
            [track] = stream.getAudioTracks();
            engine.setMedia('audio', 'sendrecv', track);

            assert.lengthOf(engine.localMediaStream.getTracks(), 1);

            return engine.createOffer();
          })
          .then(mockAnswer)
          .then((answer) => Promise.all([
            expectEvent(20000, 'track', engine),
            engine.acceptAnswer(answer)
          ]))
          .then(() => {
            assert.equal(engine.localMediaStream.getAudioTracks()[0].id, track.id);
            assert.equal(engine.localMediaStream.getAudioTracks()[0], track);
            assert.notCalled(spy);
            assertLocalMedia(engine, 'sendrecv', 'inactive');
          });
      });

      it('adds an external track without clobbering it', () => {
        let track;

        return WebRTCMediaEngine.getUserMedia({
          audio: true,
          video: false
        })
          .then((stream) => {
            [track] = stream.getAudioTracks();
            engine.setMedia('audio', 'sendrecv', track);
            engine.setMedia('video', 'sendrecv');

            assert.lengthOf(engine.localMediaStream.getTracks(), 1);

            return engine.createOffer();
          })
          .then(mockAnswer)
          .then((answer) => Promise.all([
            expectEvent(20000, 'track', engine),
            engine.acceptAnswer(answer)
          ]))
          .then(() => {
            assert.equal(engine.localMediaStream.getAudioTracks()[0].id, track.id);
            assert.equal(engine.localMediaStream.getAudioTracks()[0], track);
            assertLocalMedia(engine, 'sendrecv', 'sendrecv');
          });
      });

      it('adds a new track to an inprogress connection', () => {
        let track;

        engine.setMedia('audio', 'inactive');
        engine.setMedia('video', 'sendrecv');


        return engine.createOffer()
          .then(mockAnswer)
          .then((answer) => Promise.all([
            expectEvent(20000, 'track', engine),
            engine.acceptAnswer(answer)
          ]))
          .then(() => {
            assertLocalMedia(engine, 'inactive', 'sendrecv');
            return WebRTCMediaEngine.getUserMedia({
              audio: true,
              video: false
            });
          })
          .then((stream) => {
            [track] = stream.getAudioTracks();
            assert.isDefined(track);
            engine.setMedia('audio', 'sendrecv', track);
            return expectEvent(20000, 'negotiationneeded', engine);
          })
          .then(() => engine.createOffer())
          .then(mockRenegotiate)
          .then((answer) => engine.acceptAnswer(answer))
          .then(() => {
            assertLocalMedia(engine, 'sendrecv', 'sendrecv');
            assert.equal(engine.localMediaStream.getAudioTracks()[0].id, track.id);
            assert.equal(engine.localMediaStream.getAudioTracks()[0], track);
          });
      });
    });

    describe('custom constraints', () => {
      let engine, spy;
      beforeEach(() => {
        engine = new WebRTCMediaEngine();
        spy = sinon.spy(WebRTCMediaEngine, 'getUserMedia');
      });

      afterEach(() => {
        engine.stop();
        spy.restore();
      });


      it('starts a connection with custom constraints', () => {
        assert.notCalled(spy);
        engine.setMedia('audio', 'sendrecv');
        engine.setMedia('video', 'sendrecv', {
          facingMode: {
            ideal: 'user'
          }
        });

        return engine.createOffer()
          .then((offer) => mockAnswer(offer))
          .then((answer) => engine.acceptAnswer(answer))
          .then(() => {
            assert.calledOnce(spy);
            assert.calledWith(spy, {
              audio: true,
              video: {
                facingMode: {
                  ideal: 'user'
                }
              }
            });

            assertLocalMedia(engine, 'sendrecv', 'sendrecv');
          });
      });

      it('replaces a track with with new contraints', () => {
        assert.notCalled(spy);
        engine.setMedia('audio', 'sendrecv');
        engine.setMedia('video', 'sendrecv', {
          facingMode: {
            ideal: 'user'
          }
        });

        return engine.createOffer()
          .then((offer) => mockAnswer(offer))
          .then((answer) => engine.acceptAnswer(answer))
          .then(() => {
            assert.calledOnce(spy);
            assert.calledWithMatch(spy, {
              audio: true,
              video: {
                facingMode: {
                  ideal: 'user'
                }
              }
            });

            assertLocalMedia(engine, 'sendrecv', 'sendrecv');
            engine.setMedia('video', 'sendrecv', {
              facingMode: {
                ideal: 'environment'
              }
            });

            return expectEvent(20000, 'negotiationneeded', engine);
          })
          .then(() => engine.logger.info('creating new offer'))
          .then(() => engine.createOffer())
          .then(mockRenegotiate)
          .then((answer) => engine.acceptAnswer(answer))
          .then(() => {
            assert.calledWithMatch(spy, {
              video: {
                facingMode: {
                  ideal: 'environment'
                }
              }
            });

            assertLocalMedia(engine, 'sendrecv', 'sendrecv');
          });
      });

      it('adds a new track to an inprogress connection', () => {
        assert.notCalled(spy);
        engine.setMedia('audio', 'sendrecv');
        return engine.createOffer()
          .then((offer) => mockAnswer(offer))
          .then((answer) => engine.acceptAnswer(answer))
          .then(() => {
            assert.calledOnce(spy);

            assertLocalMedia(engine, 'sendrecv', 'inactive');
            engine.setMedia('video', 'sendrecv', {
              facingMode: {
                ideal: 'environment'
              }
            });

            return expectEvent(20000, 'negotiationneeded', engine);
          })
          .then(() => engine.createOffer())
          .then(mockRenegotiate)
          .then((answer) => engine.acceptAnswer(answer))
          .then(() => {
            assert.calledWithMatch(spy, {
              video: {
                facingMode: {
                  ideal: 'environment'
                }
              }
            });

            assertLocalMedia(engine, 'sendrecv', 'sendrecv');
          });
      });
    });

    firefoxOnly(describe)('screensharing', () => {
      let engine;

      before('create a audio-video session', () => handleErrorEvent(new WebRTCMediaEngine(), (e) => {
        engine = e;
        engine.setMedia('audio', 'sendrecv');
        engine.setMedia('video', 'sendrecv');
        return engine.createOffer()
          .then(mockAnswer)
          .then((answer) => Promise.all([
            expectEvent(20000, 'track', engine),
            engine.acceptAnswer(answer)
          ]));
      }));

      step('adds a screenshare stream', () =>
        handleErrorEvent(engine, () => Promise.resolve()
          .then(() => engine.logger.info('adding screenshare'))
          .then(() => {
            engine.setMedia('screen', 'sendonly', {
              mediaSource: 'application'
            });
            return expectEvent(1000, 'negotiationneeded', engine, 'We should receive a negotitation event when we change screen to sendonly');
          })
          .then(() => engine.createOffer())
          .then((offer) => {
            // As of FF59, setting sendonly leaves the sdp at sendrecv for the offer
            assert.equal(getMediaDirectionFromSDP('screen', offer), 'sendrecv');
            return offer;
          })
          .then(mockRenegotiate)
          .then((answer) => {
            assert.equal(getMediaDirectionFromSDP('screen', answer), 'recvonly');
            return answer;
          })
          .then((answer) => engine.acceptAnswer(answer))
          .then(() => {
            assert.lengthOf(engine.pc.getSenders().filter((s) => s.track && s.track.kind === 'video'), 2);
            assert.lengthOf(engine.pc.getSenders().filter((s) => s.track && s.track.kind === 'audio'), 1);
          })));

      step('removes the screenshare stream', () => handleErrorEvent(engine, () => {
        engine.setMedia('screen', 'inactive');
        return engine.createOffer()
          .then((offer) => {
            assert.isEmpty(engine.localScreenShare.getVideoTracks());
            // As of FF59, setting inactive leaves the sdp at recvonly for the offer
            assert.equal(getMediaDirectionFromSDP('screen', offer), 'recvonly');
            return offer;
          })
          .then(mockRenegotiate)
          .then((answer) => {
            assert.isEmpty(engine.localScreenShare.getVideoTracks());
            assert.equal(getMediaDirectionFromSDP('screen', answer), 'inactive');
            return answer;
          })
          .then((answer) => engine.acceptAnswer(answer))
          .then(() => {
            assert.isEmpty(engine.localScreenShare.getVideoTracks());
            assert.lengthOf(engine.pc.getSenders().filter((s) => s.track && s.track.kind === 'video'), 1);
            assert.lengthOf(engine.pc.getSenders().filter((s) => s.track && s.track.kind === 'audio'), 1);
          });
      }));

      step('adds back a screenshare stream', () => handleErrorEvent(engine, () => {
        assert.isEmpty(engine.localScreenShare.getVideoTracks());
        assert.lengthOf(engine.pc.getSenders().filter((s) => s.track && s.track.kind === 'video'), 1);
        assert.lengthOf(engine.pc.getSenders().filter((s) => s.track && s.track.kind === 'audio'), 1);

        engine.setMedia('screen', 'sendonly');

        assert.lengthOf(engine.pc.getSenders().filter((s) => s.track && s.track.kind === 'video'), 1);
        assert.lengthOf(engine.pc.getSenders().filter((s) => s.track && s.track.kind === 'audio'), 1);

        return engine.createOffer()
          .then((offer) => {
            assert.lengthOf(engine.pc.getSenders().filter((s) => s.track && s.track.kind === 'audio'), 1, 'There should be an audio sender after creating the offer');
            assert.isTrue(engine.pc.getSenders().find((s) => s.track && s.track.kind === 'audio').track.enabled, 'The audio sender should be enabled');
            assert.lengthOf(engine.pc.getSenders().filter((s) => s.track && s.track.kind === 'video'), 2, 'There should be 2 video senders after creating the offer');
            assert.isTrue(engine.pc.getSenders().filter((s) => s.track && s.track.kind === 'video')[0].track.enabled, 'The video sender should be enabled');
            assert.isTrue(engine.pc.getSenders().filter((s) => s.track && s.track.kind === 'video')[1].track.enabled, 'The screenshare sender should be enabled');

            // As of FF59, setting sendonly leaves the sdp at sendrecv for the offer
            assert.equal(getMediaDirectionFromSDP('audio', offer), 'sendrecv');
            assert.equal(getMediaDirectionFromSDP('video', offer), 'sendrecv');
            assert.equal(getMediaDirectionFromSDP('screen', offer), 'sendrecv');
            return offer;
          })
          .then(mockRenegotiate)
          .then((answer) => {
            assert.equal(getMediaDirectionFromSDP('screen', answer), 'recvonly');
            return answer;
          })
          .then((answer) => engine.acceptAnswer(answer))
          .then(() => {
            assert.lengthOf(engine.pc.getSenders().filter((s) => s.track && s.track.kind === 'video'), 2);
            assert.lengthOf(engine.pc.getSenders().filter((s) => s.track && s.track.kind === 'audio'), 1);
          });
      }));
    });
  });
});

function assertLocalKind(kind, direction, engine) {
  if (engine.localMediaStream) {
    const tracks = engine.localMediaStream.getTracks().filter((t) => t.kind === kind);
    if (direction.includes('send')) {
      assert.lengthOf(tracks, 1, `there is 1 local ${kind} track`);
      assert.isTrue(tracks[0].enabled, `the local ${kind} track is enabled`);
    }
    else {
      try {
        assert.lengthOf(tracks, 0, `there are 0 local ${kind} tracks`);
      }
      catch (err) {
        assert.lengthOf(tracks, 1, `there is 1 local ${kind} track`);
        assert.isFalse(tracks[0].enabled, `the local ${kind} track is not enabled`);
      }
    }
  }


  const senders = engine.pc.getSenders().filter((s) => s.track && s.track.kind === kind);
  if (direction.includes('send')) {
    assert.lengthOf(senders, 1, `local ${kind} is ${direction}`);
    assert.isTrue(senders[0].track.enabled, `local ${kind}is ${direction}`);
  }
  else {
    try {
      assert.lengthOf(senders, 0, `there are 0 ${kind} senders`);
    }
    catch (err) {
      assert.lengthOf(senders, 1, `local ${kind} is ${direction}`);
      assert.isFalse(senders[0].track.enabled, `local ${kind}is ${direction}`);
    }
  }
}

function assertRemoteKind(kind, direction, engine) {
  if (engine.remoteMediaStream) {
    const tracks = engine.remoteMediaStream.getTracks().filter((t) => t.kind === kind);
    if (direction.includes('recv')) {
      assert.lengthOf(tracks, 1, `there is 1 remote ${kind} track`);
      assert.isTrue(tracks[0].enabled, `the remote ${kind} track is enabled`);
    }
    else {
      try {
        assert.lengthOf(tracks, 0, `there are 0 remote ${kind} tracks`);
      }
      catch (err) {
        assert.lengthOf(tracks, 1, `there is 1 remote ${kind} track`);
        assert.isFalse(tracks[0].enabled, `the remote ${kind} track is not enabled`);
      }
    }
  }
  // There's some commented code here with two different attempts at adding some
  // assertions, but they don't hold in Chrome. Once Chrome gets receivers
  // working correctly, hopefully we can drop the streams stuff and rely
  // entirely on receiver assertions
  // const pcTracks = engine.pc.getRemoteStreams[0] && engine.pc.getRemoteStreams[0].getTracks().filter((t) => t.kind === kind);
  const receivers = engine.pc.getReceivers().filter((r) => r.track.kind === kind);

  if (direction.includes('recv')) {
    // assert.isDefined(pcTracks, `the peer connection has remote tracks`);
    // assert.lengthOf(pcTracks, 1, `there is 1 remote ${kind} track`);
    // assert.isTrue(pcTracks[0].enabled, `the remote ${kind} track is enabled`);


    // try {
    //   assert.lengthOf(receivers, 1, `there is 1 ${kind} receiver`);
    //   assert.isTrue(receivers[0].track.enabled, `the remote ${kind} receiver's track is enabled`);
    // }
    // catch (err) {
    //   assert.lengthOf(engine.pc.getRemoteStreams(), 1, `There is a remote stream`);
    //   assert.lengthOf(engine.pc.getRemoteStreams()[0].getTracks().filter((t) => t.kind === kind), 1, `There is 1 ${kind} track in the remote stream`);
    //   assert.isTrue(engine.pc.getRemoteStreams()[0].getTracks().find((t) => t.kind === kind).enabled, `The is ${kind} track in the remote stream is enabled`);
    // }
  }
  else {
    try {
      assert.lengthOf(receivers, 0, `there are 0 ${kind} receivers`);
    }
    catch (err) {
      assert.lengthOf(receivers, 1, `there is 1 ${kind} receivers`);
      assert.isFalse(receivers[0].track.enabled, `the remote ${kind} receiver's track is not enabled`);
    }
  }
}

function assertLocalMedia(engine, targetAudioDirection, targetVideoDirection) {
  assertLocalKind('audio', targetAudioDirection, engine);
  assertLocalKind('video', targetVideoDirection, engine);
}

function assertRemoteMedia(engine, targetAudioDirection, targetVideoDirection) {
  assertRemoteKind('audio', targetAudioDirection, engine);
  assertRemoteKind('video', targetVideoDirection, engine);
}

function assertOffer(kind, currentDirection, previousDirection, offer) {
  const sdpDirection = getMediaDirectionFromSDP(kind, offer);

  const fallbackDirection = getExpectedMediaDirection(currentDirection, previousDirection);
  const media = getMediaFromSDP(kind, offer, currentDirection);
  // Don't wire up the fallback assertion if it wouldn't do any good (this helps
  // with line numbers)
  if (fallbackDirection === currentDirection) {
    if (currentDirection === 'inactive') {
      // Chrome and firefox behave differently with inactive media.
      // We can use the result from getMediaDirectionFromSDP instead of getMediaFromSDP
      // for inactive direction.
      assert.equal(sdpDirection, currentDirection, `expected "${kind}" offer to include "${currentDirection}"`);
    }
    else {
      // Since getMediaDirectionFromSDP doesn't support multiple media sections in sdp,
      // we use getMediaFromSDP to find the appropriate section
      assert.isDefined(media, `expected "${kind}" offer to be "${currentDirection}"`);
    }
    return;
  }

  try {
    if (currentDirection === 'inactive') {
      assert.equal(sdpDirection, currentDirection, `expected "${kind}" offer to include "${currentDirection}"`);
    }
    else {
      assert.isDefined(media, `expected "${kind}" offer to have "${currentDirection}"`);
    }
  }
  catch (err) {
    assert.equal(sdpDirection, fallbackDirection, `expected "${kind}" offer to include "${currentDirection}" or "${fallbackDirection}"`);
  }
}

function assertAnswer(kind, currentDirection, previousDirection, answer) {
  const sdpDirection = getMediaDirectionFromSDP(kind, answer);

  const currentAnswerDirection = reverseMediaDirection(currentDirection);
  const fallbackDirection = reverseMediaDirection(getExpectedMediaDirection(currentDirection, previousDirection));

  const media = getMediaFromSDP(kind, answer, currentAnswerDirection);
  // Don't wire up the fallback assertion if it wouldn't do any good (this helps
  // with line numbers)
  if (currentAnswerDirection === fallbackDirection) {
    if (currentAnswerDirection === 'inactive') {
      // Chrome and firefox behave differently with inactive media.
      // We can use the result from getMediaDirectionFromSDP instead of getMediaFromSDP
      // for inactive direction.
      assert.equal(sdpDirection, currentAnswerDirection, `expected "${kind}" offer to include "${currentAnswerDirection}"`);
    }
    else {
      // Since getMediaDirectionFromSDP doesn't support multiple media sections in sdp,
      // we use getMediaFromSDP to find the appropriate section

      assert.isDefined(media, `expected "${kind}" answer to have "${currentAnswerDirection}"`);
    }
    return;
  }

  try {
    if (currentAnswerDirection === 'inactive') {
      assert.equal(sdpDirection, currentAnswerDirection, `expected "${kind}" offer to include "${currentAnswerDirection}"`);
    }
    else {
      assert.isDefined(media, `expected "${kind}" answer to have "${currentAnswerDirection}"`);
    }
  }
  catch (err) {
    assert.equal(sdpDirection, fallbackDirection, `expected "${kind}" answer to include "${currentAnswerDirection}" or "${fallbackDirection}"`);
  }
}

function assertSpyCalledOrNot(expectCall, spy) {
  if (expectCall) {
    assert.called(spy);
  }
  else {
    assert.notCalled(spy);
  }
}
